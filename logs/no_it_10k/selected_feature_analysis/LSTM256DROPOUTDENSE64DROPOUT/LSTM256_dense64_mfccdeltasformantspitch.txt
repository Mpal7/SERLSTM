
EXECUTION PARAMETERS: {NUMBER OF FOLDERS:  10 }-{NUMBER OF EPOCHS:  80 }-{NUMBER OF ROUTINE ITERATIONS:  1 }-{BATCH SIZE :  32 }-{SIGNAL MODE:  fp }-{AUGMENT: Sad }-{FEATURES:  ('mfcc', 'deltas', 'formants', 'pitch') }-{EMOTIONS: ('Sad', 'Happy', 'Angry', 'Neutral') }

####ITERATION NUMBER:  1

#####FOLDER NUMBER: 1
Starting LSTM
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 44, 30)            0         
_________________________________________________________________
lstm (LSTM)                  (None, 256)               293888    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 64)                16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 260       
=================================================================
Total params: 310,596
Trainable params: 310,596
Non-trainable params: 0
_________________________________________________________________
Epoch 1/80
10/10 - 6s - loss: 1.7467 - accuracy: 0.2550 - val_loss: 1.4282 - val_accuracy: 0.2353
Epoch 2/80
10/10 - 2s - loss: 1.8003 - accuracy: 0.2119 - val_loss: 1.3792 - val_accuracy: 0.2941
Epoch 3/80
10/10 - 2s - loss: 1.6477 - accuracy: 0.2715 - val_loss: 1.4164 - val_accuracy: 0.2647
Epoch 4/80
10/10 - 2s - loss: 1.5760 - accuracy: 0.2947 - val_loss: 1.4048 - val_accuracy: 0.2059
Epoch 5/80
10/10 - 2s - loss: 1.5864 - accuracy: 0.2616 - val_loss: 1.3468 - val_accuracy: 0.3824
Epoch 6/80
10/10 - 2s - loss: 1.5796 - accuracy: 0.2682 - val_loss: 1.3060 - val_accuracy: 0.4118
Epoch 7/80
10/10 - 2s - loss: 1.5094 - accuracy: 0.2848 - val_loss: 1.2942 - val_accuracy: 0.3529
Epoch 8/80
10/10 - 2s - loss: 1.6157 - accuracy: 0.2483 - val_loss: 1.2995 - val_accuracy: 0.3529
Epoch 9/80
10/10 - 2s - loss: 1.5225 - accuracy: 0.2848 - val_loss: 1.3098 - val_accuracy: 0.3529
Epoch 10/80
10/10 - 2s - loss: 1.5722 - accuracy: 0.2815 - val_loss: 1.3210 - val_accuracy: 0.2941
Epoch 11/80
10/10 - 2s - loss: 1.5276 - accuracy: 0.2848 - val_loss: 1.3178 - val_accuracy: 0.3529
Epoch 12/80
10/10 - 2s - loss: 1.5230 - accuracy: 0.2517 - val_loss: 1.2971 - val_accuracy: 0.3529
Epoch 13/80
10/10 - 2s - loss: 1.4679 - accuracy: 0.2947 - val_loss: 1.3120 - val_accuracy: 0.3235
Epoch 14/80
10/10 - 2s - loss: 1.4514 - accuracy: 0.3179 - val_loss: 1.2874 - val_accuracy: 0.3824
Epoch 15/80
10/10 - 1s - loss: 1.4416 - accuracy: 0.3179 - val_loss: 1.2756 - val_accuracy: 0.3824
Epoch 16/80
10/10 - 1s - loss: 1.4762 - accuracy: 0.3113 - val_loss: 1.3022 - val_accuracy: 0.3529
Epoch 17/80
10/10 - 2s - loss: 1.5022 - accuracy: 0.2848 - val_loss: 1.3248 - val_accuracy: 0.3235
Epoch 18/80
10/10 - 2s - loss: 1.4601 - accuracy: 0.2848 - val_loss: 1.3402 - val_accuracy: 0.2941
Epoch 19/80
10/10 - 2s - loss: 1.4638 - accuracy: 0.2848 - val_loss: 1.3227 - val_accuracy: 0.3824
Epoch 20/80
10/10 - 3s - loss: 1.4750 - accuracy: 0.3212 - val_loss: 1.3523 - val_accuracy: 0.2647
Epoch 21/80
10/10 - 2s - loss: 1.4345 - accuracy: 0.3079 - val_loss: 1.3284 - val_accuracy: 0.3824
Epoch 22/80
10/10 - 2s - loss: 1.4291 - accuracy: 0.3013 - val_loss: 1.3198 - val_accuracy: 0.3529
Epoch 23/80
10/10 - 2s - loss: 1.4417 - accuracy: 0.3113 - val_loss: 1.3170 - val_accuracy: 0.4118
Epoch 24/80
10/10 - 2s - loss: 1.4268 - accuracy: 0.2682 - val_loss: 1.3073 - val_accuracy: 0.3824
Epoch 25/80
10/10 - 3s - loss: 1.4196 - accuracy: 0.2781 - val_loss: 1.2830 - val_accuracy: 0.5000
Epoch 26/80
10/10 - 2s - loss: 1.5146 - accuracy: 0.2517 - val_loss: 1.3029 - val_accuracy: 0.4412
Epoch 27/80
10/10 - 2s - loss: 1.4620 - accuracy: 0.2914 - val_loss: 1.3478 - val_accuracy: 0.3235
Epoch 28/80
10/10 - 2s - loss: 1.4088 - accuracy: 0.3179 - val_loss: 1.3210 - val_accuracy: 0.3235
Epoch 29/80
10/10 - 2s - loss: 1.4649 - accuracy: 0.2550 - val_loss: 1.3305 - val_accuracy: 0.3529
Epoch 30/80
10/10 - 2s - loss: 1.3816 - accuracy: 0.3245 - val_loss: 1.3214 - val_accuracy: 0.4118
Epoch 31/80
10/10 - 2s - loss: 1.4578 - accuracy: 0.2848 - val_loss: 1.3431 - val_accuracy: 0.3235
Epoch 32/80
10/10 - 2s - loss: 1.4030 - accuracy: 0.2848 - val_loss: 1.3239 - val_accuracy: 0.2941
Epoch 33/80
10/10 - 2s - loss: 1.4175 - accuracy: 0.3146 - val_loss: 1.2900 - val_accuracy: 0.5000
Epoch 34/80
10/10 - 2s - loss: 1.4076 - accuracy: 0.2980 - val_loss: 1.3020 - val_accuracy: 0.3529
Epoch 35/80
10/10 - 2s - loss: 1.4163 - accuracy: 0.3245 - val_loss: 1.3203 - val_accuracy: 0.4412
Epoch 36/80
10/10 - 3s - loss: 1.4543 - accuracy: 0.2947 - val_loss: 1.3368 - val_accuracy: 0.2647
Epoch 37/80
10/10 - 2s - loss: 1.4504 - accuracy: 0.2616 - val_loss: 1.3388 - val_accuracy: 0.2647
Epoch 38/80
10/10 - 2s - loss: 1.4495 - accuracy: 0.2517 - val_loss: 1.3385 - val_accuracy: 0.2647
Epoch 39/80
10/10 - 2s - loss: 1.3722 - accuracy: 0.3013 - val_loss: 1.3277 - val_accuracy: 0.2059
Epoch 40/80
10/10 - 2s - loss: 1.4178 - accuracy: 0.2815 - val_loss: 1.3354 - val_accuracy: 0.2941
Epoch 41/80
10/10 - 3s - loss: 1.4203 - accuracy: 0.3245 - val_loss: 1.3207 - val_accuracy: 0.3824
Epoch 42/80
10/10 - 2s - loss: 1.3980 - accuracy: 0.3212 - val_loss: 1.3435 - val_accuracy: 0.2059
Epoch 43/80
10/10 - 2s - loss: 1.4418 - accuracy: 0.2616 - val_loss: 1.3548 - val_accuracy: 0.2647
Epoch 44/80
10/10 - 2s - loss: 1.4572 - accuracy: 0.2450 - val_loss: 1.3474 - val_accuracy: 0.4706
Epoch 45/80
10/10 - 2s - loss: 1.3962 - accuracy: 0.3013 - val_loss: 1.3339 - val_accuracy: 0.3235
Epoch 00045: early stopping
best epoch: 25  loss: 1.2830241918563843  acc: 0.5
[1.2830241918563843] [0.5]
Accuracy:0.500

Confusion matrix:
 [[ 1  5  0  2]
 [ 0 10  2  0]
 [ 0  4  3  2]
 [ 0  2  0  3]]

#####FOLDER NUMBER: 2
Epoch 1/80
10/10 - 2s - loss: 1.7265 - accuracy: 0.2351 - val_loss: 1.4384 - val_accuracy: 0.2647
Epoch 2/80
10/10 - 2s - loss: 1.5962 - accuracy: 0.2682 - val_loss: 1.4316 - val_accuracy: 0.2647
Epoch 3/80
10/10 - 2s - loss: 1.5627 - accuracy: 0.2881 - val_loss: 1.3658 - val_accuracy: 0.2353
Epoch 4/80
10/10 - 2s - loss: 1.5910 - accuracy: 0.2649 - val_loss: 1.3933 - val_accuracy: 0.2647
Epoch 5/80
10/10 - 2s - loss: 1.5435 - accuracy: 0.2715 - val_loss: 1.3847 - val_accuracy: 0.2353
Epoch 6/80
10/10 - 2s - loss: 1.4914 - accuracy: 0.2781 - val_loss: 1.3242 - val_accuracy: 0.3529
Epoch 7/80
10/10 - 2s - loss: 1.4747 - accuracy: 0.3046 - val_loss: 1.4213 - val_accuracy: 0.1471
Epoch 8/80
10/10 - 2s - loss: 1.5366 - accuracy: 0.2815 - val_loss: 1.4225 - val_accuracy: 0.1765
Epoch 9/80
10/10 - 2s - loss: 1.5130 - accuracy: 0.2682 - val_loss: 1.3570 - val_accuracy: 0.3824
Epoch 10/80
10/10 - 2s - loss: 1.5338 - accuracy: 0.2649 - val_loss: 1.3767 - val_accuracy: 0.2059
Epoch 11/80
10/10 - 2s - loss: 1.4967 - accuracy: 0.2450 - val_loss: 1.3884 - val_accuracy: 0.2353
Epoch 12/80
10/10 - 2s - loss: 1.5024 - accuracy: 0.2815 - val_loss: 1.3340 - val_accuracy: 0.3529
Epoch 13/80
10/10 - 2s - loss: 1.4687 - accuracy: 0.2848 - val_loss: 1.3277 - val_accuracy: 0.4118
Epoch 14/80
10/10 - 1s - loss: 1.5170 - accuracy: 0.2682 - val_loss: 1.4133 - val_accuracy: 0.0882
Epoch 15/80
10/10 - 1s - loss: 1.5041 - accuracy: 0.2285 - val_loss: 1.4201 - val_accuracy: 0.1471
Epoch 16/80
10/10 - 1s - loss: 1.4800 - accuracy: 0.2483 - val_loss: 1.3742 - val_accuracy: 0.2353
Epoch 17/80
10/10 - 2s - loss: 1.5172 - accuracy: 0.2450 - val_loss: 1.3614 - val_accuracy: 0.2941
Epoch 18/80
10/10 - 2s - loss: 1.4065 - accuracy: 0.2947 - val_loss: 1.3731 - val_accuracy: 0.2353
Epoch 19/80
10/10 - 2s - loss: 1.4670 - accuracy: 0.2781 - val_loss: 1.3969 - val_accuracy: 0.3824
Epoch 20/80
10/10 - 2s - loss: 1.4344 - accuracy: 0.2914 - val_loss: 1.4221 - val_accuracy: 0.2059
Epoch 21/80
10/10 - 2s - loss: 1.4099 - accuracy: 0.3146 - val_loss: 1.3689 - val_accuracy: 0.2059
Epoch 22/80
10/10 - 2s - loss: 1.4513 - accuracy: 0.2715 - val_loss: 1.3797 - val_accuracy: 0.2647
Epoch 23/80
10/10 - 2s - loss: 1.3811 - accuracy: 0.3179 - val_loss: 1.3919 - val_accuracy: 0.2941
Epoch 24/80
10/10 - 2s - loss: 1.4414 - accuracy: 0.2815 - val_loss: 1.3715 - val_accuracy: 0.3235
Epoch 25/80
10/10 - 2s - loss: 1.4315 - accuracy: 0.2914 - val_loss: 1.4013 - val_accuracy: 0.2059
Epoch 26/80
10/10 - 2s - loss: 1.4514 - accuracy: 0.2781 - val_loss: 1.3628 - val_accuracy: 0.4118
Epoch 27/80
10/10 - 2s - loss: 1.4205 - accuracy: 0.2881 - val_loss: 1.3500 - val_accuracy: 0.3529
Epoch 28/80
10/10 - 2s - loss: 1.4211 - accuracy: 0.3079 - val_loss: 1.3526 - val_accuracy: 0.2647
Epoch 29/80
10/10 - 2s - loss: 1.4159 - accuracy: 0.2848 - val_loss: 1.3814 - val_accuracy: 0.2941
Epoch 30/80
10/10 - 2s - loss: 1.4253 - accuracy: 0.3609 - val_loss: 1.3543 - val_accuracy: 0.4118
Epoch 31/80
10/10 - 2s - loss: 1.4331 - accuracy: 0.2417 - val_loss: 1.3974 - val_accuracy: 0.3235
Epoch 32/80
10/10 - 2s - loss: 1.4520 - accuracy: 0.2848 - val_loss: 1.3855 - val_accuracy: 0.2941
Epoch 33/80
10/10 - 2s - loss: 1.4332 - accuracy: 0.2848 - val_loss: 1.3404 - val_accuracy: 0.3235
Epoch 00033: early stopping
best epoch: 13  loss: 1.3276787996292114  acc: 0.4117647111415863
[1.2830241918563843, 1.3276787996292114] [0.5, 0.4117647111415863]
Accuracy:0.412

Confusion matrix:
 [[ 0  1  0  3]
 [ 0 10  0  2]
 [ 0  5  0  2]
 [ 0  6  1  4]]

#####FOLDER NUMBER: 3
Epoch 1/80
10/10 - 3s - loss: 1.7587 - accuracy: 0.2351 - val_loss: 1.4162 - val_accuracy: 0.2353
Epoch 2/80
10/10 - 3s - loss: 1.6339 - accuracy: 0.2881 - val_loss: 1.4230 - val_accuracy: 0.2059
Epoch 3/80
10/10 - 2s - loss: 1.6116 - accuracy: 0.2517 - val_loss: 1.3762 - val_accuracy: 0.2059
Epoch 4/80
10/10 - 2s - loss: 1.5280 - accuracy: 0.3079 - val_loss: 1.3454 - val_accuracy: 0.2941
Epoch 5/80
10/10 - 2s - loss: 1.5782 - accuracy: 0.2616 - val_loss: 1.3329 - val_accuracy: 0.3235
Epoch 6/80
10/10 - 2s - loss: 1.5662 - accuracy: 0.2815 - val_loss: 1.3350 - val_accuracy: 0.3529
Epoch 7/80
10/10 - 2s - loss: 1.5576 - accuracy: 0.2583 - val_loss: 1.3492 - val_accuracy: 0.2941
Epoch 8/80
10/10 - 2s - loss: 1.5028 - accuracy: 0.2881 - val_loss: 1.3365 - val_accuracy: 0.4412
Epoch 9/80
10/10 - 2s - loss: 1.5146 - accuracy: 0.2980 - val_loss: 1.3674 - val_accuracy: 0.2353
Epoch 10/80
10/10 - 3s - loss: 1.4507 - accuracy: 0.3013 - val_loss: 1.3595 - val_accuracy: 0.2059
Epoch 11/80
10/10 - 3s - loss: 1.5497 - accuracy: 0.2781 - val_loss: 1.3424 - val_accuracy: 0.3529
Epoch 12/80
10/10 - 2s - loss: 1.5550 - accuracy: 0.2219 - val_loss: 1.3695 - val_accuracy: 0.2353
Epoch 13/80
10/10 - 2s - loss: 1.4725 - accuracy: 0.2682 - val_loss: 1.3796 - val_accuracy: 0.2059
Epoch 14/80
10/10 - 2s - loss: 1.4860 - accuracy: 0.2483 - val_loss: 1.3310 - val_accuracy: 0.3235
Epoch 15/80
10/10 - 2s - loss: 1.5123 - accuracy: 0.2649 - val_loss: 1.3602 - val_accuracy: 0.2941
Epoch 16/80
10/10 - 2s - loss: 1.4549 - accuracy: 0.3046 - val_loss: 1.3841 - val_accuracy: 0.2059
Epoch 17/80
10/10 - 2s - loss: 1.4647 - accuracy: 0.2815 - val_loss: 1.4043 - val_accuracy: 0.2059
Epoch 18/80
10/10 - 2s - loss: 1.4934 - accuracy: 0.2318 - val_loss: 1.3681 - val_accuracy: 0.2353
Epoch 19/80
10/10 - 2s - loss: 1.4429 - accuracy: 0.2748 - val_loss: 1.3549 - val_accuracy: 0.2353
Epoch 20/80
10/10 - 2s - loss: 1.4980 - accuracy: 0.2550 - val_loss: 1.3399 - val_accuracy: 0.2941
Epoch 21/80
10/10 - 2s - loss: 1.5070 - accuracy: 0.2351 - val_loss: 1.3805 - val_accuracy: 0.2353
Epoch 22/80
10/10 - 2s - loss: 1.4504 - accuracy: 0.2914 - val_loss: 1.3853 - val_accuracy: 0.2059
Epoch 23/80
10/10 - 2s - loss: 1.4404 - accuracy: 0.2848 - val_loss: 1.3632 - val_accuracy: 0.2941
Epoch 24/80
10/10 - 2s - loss: 1.4025 - accuracy: 0.2881 - val_loss: 1.3767 - val_accuracy: 0.2941
Epoch 25/80
10/10 - 2s - loss: 1.4325 - accuracy: 0.3278 - val_loss: 1.3515 - val_accuracy: 0.2941
Epoch 26/80
10/10 - 2s - loss: 1.4266 - accuracy: 0.2781 - val_loss: 1.3663 - val_accuracy: 0.2647
Epoch 27/80
10/10 - 2s - loss: 1.4332 - accuracy: 0.2980 - val_loss: 1.3496 - val_accuracy: 0.3824
Epoch 28/80
10/10 - 2s - loss: 1.4231 - accuracy: 0.3013 - val_loss: 1.3392 - val_accuracy: 0.3824
Epoch 00028: early stopping
best epoch: 8  loss: 1.3364826440811157  acc: 0.44117647409439087
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157] [0.5, 0.4117647111415863, 0.44117647409439087]
Accuracy:0.441

Confusion matrix:
 [[7 0 2 1]
 [1 0 6 0]
 [0 0 6 2]
 [4 0 3 2]]

#####FOLDER NUMBER: 4
Epoch 1/80
10/10 - 3s - loss: 1.6503 - accuracy: 0.2881 - val_loss: 1.3611 - val_accuracy: 0.2647
Epoch 2/80
10/10 - 3s - loss: 1.7782 - accuracy: 0.1987 - val_loss: 1.3497 - val_accuracy: 0.2353
Epoch 3/80
10/10 - 2s - loss: 1.6172 - accuracy: 0.2583 - val_loss: 1.4303 - val_accuracy: 0.2353
Epoch 4/80
10/10 - 2s - loss: 1.6858 - accuracy: 0.2616 - val_loss: 1.4096 - val_accuracy: 0.2059
Epoch 5/80
10/10 - 2s - loss: 1.6332 - accuracy: 0.2450 - val_loss: 1.3841 - val_accuracy: 0.3529
Epoch 6/80
10/10 - 2s - loss: 1.5618 - accuracy: 0.2682 - val_loss: 1.3843 - val_accuracy: 0.2941
Epoch 7/80
10/10 - 2s - loss: 1.5337 - accuracy: 0.2649 - val_loss: 1.3908 - val_accuracy: 0.1176
Epoch 8/80
10/10 - 2s - loss: 1.5320 - accuracy: 0.2450 - val_loss: 1.3700 - val_accuracy: 0.3529
Epoch 9/80
10/10 - 2s - loss: 1.5272 - accuracy: 0.2815 - val_loss: 1.3897 - val_accuracy: 0.2353
Epoch 10/80
10/10 - 2s - loss: 1.5226 - accuracy: 0.2715 - val_loss: 1.3122 - val_accuracy: 0.3529
Epoch 11/80
10/10 - 2s - loss: 1.5366 - accuracy: 0.2517 - val_loss: 1.3938 - val_accuracy: 0.1471
Epoch 12/80
10/10 - 2s - loss: 1.5143 - accuracy: 0.2748 - val_loss: 1.4255 - val_accuracy: 0.1765
Epoch 13/80
10/10 - 2s - loss: 1.4872 - accuracy: 0.2848 - val_loss: 1.3615 - val_accuracy: 0.2941
Epoch 14/80
10/10 - 2s - loss: 1.4465 - accuracy: 0.3146 - val_loss: 1.3272 - val_accuracy: 0.3824
Epoch 15/80
10/10 - 2s - loss: 1.4408 - accuracy: 0.2947 - val_loss: 1.3961 - val_accuracy: 0.2059
Epoch 16/80
10/10 - 2s - loss: 1.4462 - accuracy: 0.2715 - val_loss: 1.3932 - val_accuracy: 0.2353
Epoch 17/80
10/10 - 2s - loss: 1.4604 - accuracy: 0.2715 - val_loss: 1.3701 - val_accuracy: 0.3529
Epoch 18/80
10/10 - 2s - loss: 1.4092 - accuracy: 0.3046 - val_loss: 1.3876 - val_accuracy: 0.1176
Epoch 19/80
10/10 - 2s - loss: 1.4737 - accuracy: 0.2483 - val_loss: 1.3858 - val_accuracy: 0.2059
Epoch 20/80
10/10 - 2s - loss: 1.4611 - accuracy: 0.2682 - val_loss: 1.3822 - val_accuracy: 0.2353
Epoch 21/80
10/10 - 2s - loss: 1.4662 - accuracy: 0.2781 - val_loss: 1.4002 - val_accuracy: 0.1471
Epoch 22/80
10/10 - 2s - loss: 1.4492 - accuracy: 0.2781 - val_loss: 1.4116 - val_accuracy: 0.2059
Epoch 23/80
10/10 - 2s - loss: 1.4845 - accuracy: 0.2450 - val_loss: 1.4083 - val_accuracy: 0.1765
Epoch 24/80
10/10 - 2s - loss: 1.4309 - accuracy: 0.2881 - val_loss: 1.3851 - val_accuracy: 0.2059
Epoch 25/80
10/10 - 2s - loss: 1.4763 - accuracy: 0.2781 - val_loss: 1.3935 - val_accuracy: 0.2059
Epoch 26/80
10/10 - 2s - loss: 1.4205 - accuracy: 0.2947 - val_loss: 1.3986 - val_accuracy: 0.1765
Epoch 27/80
10/10 - 2s - loss: 1.3972 - accuracy: 0.3411 - val_loss: 1.4216 - val_accuracy: 0.1471
Epoch 28/80
10/10 - 2s - loss: 1.4325 - accuracy: 0.2715 - val_loss: 1.3863 - val_accuracy: 0.1176
Epoch 29/80
10/10 - 3s - loss: 1.4061 - accuracy: 0.3113 - val_loss: 1.3495 - val_accuracy: 0.2647
Epoch 30/80
10/10 - 2s - loss: 1.4655 - accuracy: 0.2483 - val_loss: 1.3926 - val_accuracy: 0.1176
Epoch 31/80
10/10 - 2s - loss: 1.4125 - accuracy: 0.2980 - val_loss: 1.3895 - val_accuracy: 0.2353
Epoch 32/80
10/10 - 2s - loss: 1.4011 - accuracy: 0.3146 - val_loss: 1.3866 - val_accuracy: 0.2059
Epoch 33/80
10/10 - 2s - loss: 1.4373 - accuracy: 0.2980 - val_loss: 1.3973 - val_accuracy: 0.2353
Epoch 34/80
10/10 - 3s - loss: 1.4178 - accuracy: 0.2848 - val_loss: 1.3701 - val_accuracy: 0.2353
Epoch 00034: early stopping
best epoch: 14  loss: 1.3272067308425903  acc: 0.38235294818878174
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174]
Accuracy:0.382

Confusion matrix:
 [[3 0 4 1]
 [1 1 3 2]
 [1 2 8 1]
 [4 1 1 1]]

#####FOLDER NUMBER: 5
Epoch 1/80
10/10 - 2s - loss: 1.7572 - accuracy: 0.2318 - val_loss: 1.4468 - val_accuracy: 0.3235
Epoch 2/80
10/10 - 2s - loss: 1.6243 - accuracy: 0.2682 - val_loss: 1.4074 - val_accuracy: 0.2647
Epoch 3/80
10/10 - 2s - loss: 1.6009 - accuracy: 0.2715 - val_loss: 1.3657 - val_accuracy: 0.2353
Epoch 4/80
10/10 - 2s - loss: 1.6518 - accuracy: 0.2583 - val_loss: 1.4096 - val_accuracy: 0.2059
Epoch 5/80
10/10 - 2s - loss: 1.5745 - accuracy: 0.2550 - val_loss: 1.4045 - val_accuracy: 0.2353
Epoch 6/80
10/10 - 2s - loss: 1.5249 - accuracy: 0.2848 - val_loss: 1.3583 - val_accuracy: 0.2647
Epoch 7/80
10/10 - 2s - loss: 1.5077 - accuracy: 0.2616 - val_loss: 1.3574 - val_accuracy: 0.2941
Epoch 8/80
10/10 - 2s - loss: 1.4821 - accuracy: 0.2947 - val_loss: 1.3747 - val_accuracy: 0.2647
Epoch 9/80
10/10 - 2s - loss: 1.5726 - accuracy: 0.1954 - val_loss: 1.3795 - val_accuracy: 0.2353
Epoch 10/80
10/10 - 2s - loss: 1.5357 - accuracy: 0.2881 - val_loss: 1.3422 - val_accuracy: 0.2941
Epoch 11/80
10/10 - 2s - loss: 1.4985 - accuracy: 0.2517 - val_loss: 1.3542 - val_accuracy: 0.2353
Epoch 12/80
10/10 - 2s - loss: 1.4704 - accuracy: 0.2980 - val_loss: 1.4634 - val_accuracy: 0.1471
Epoch 13/80
10/10 - 2s - loss: 1.4635 - accuracy: 0.3013 - val_loss: 1.3858 - val_accuracy: 0.3529
Epoch 14/80
10/10 - 3s - loss: 1.4966 - accuracy: 0.2715 - val_loss: 1.3866 - val_accuracy: 0.2353
Epoch 15/80
10/10 - 2s - loss: 1.4965 - accuracy: 0.2417 - val_loss: 1.3513 - val_accuracy: 0.3824
Epoch 16/80
10/10 - 2s - loss: 1.4461 - accuracy: 0.2980 - val_loss: 1.3461 - val_accuracy: 0.2647
Epoch 17/80
10/10 - 2s - loss: 1.4963 - accuracy: 0.2616 - val_loss: 1.3526 - val_accuracy: 0.3235
Epoch 18/80
10/10 - 2s - loss: 1.5110 - accuracy: 0.1954 - val_loss: 1.3664 - val_accuracy: 0.2059
Epoch 19/80
10/10 - 2s - loss: 1.4707 - accuracy: 0.2715 - val_loss: 1.3769 - val_accuracy: 0.1765
Epoch 20/80
10/10 - 2s - loss: 1.4960 - accuracy: 0.2285 - val_loss: 1.3491 - val_accuracy: 0.2941
Epoch 21/80
10/10 - 2s - loss: 1.4291 - accuracy: 0.2980 - val_loss: 1.3693 - val_accuracy: 0.3235
Epoch 22/80
10/10 - 2s - loss: 1.4554 - accuracy: 0.2848 - val_loss: 1.3864 - val_accuracy: 0.3235
Epoch 23/80
10/10 - 2s - loss: 1.4452 - accuracy: 0.3079 - val_loss: 1.3585 - val_accuracy: 0.3235
Epoch 24/80
10/10 - 2s - loss: 1.4267 - accuracy: 0.2914 - val_loss: 1.3561 - val_accuracy: 0.2647
Epoch 25/80
10/10 - 2s - loss: 1.4444 - accuracy: 0.2450 - val_loss: 1.3356 - val_accuracy: 0.2941
Epoch 26/80
10/10 - 2s - loss: 1.4483 - accuracy: 0.3212 - val_loss: 1.3884 - val_accuracy: 0.2059
Epoch 27/80
10/10 - 2s - loss: 1.4440 - accuracy: 0.2682 - val_loss: 1.3484 - val_accuracy: 0.2941
Epoch 28/80
10/10 - 2s - loss: 1.4008 - accuracy: 0.3179 - val_loss: 1.3658 - val_accuracy: 0.2941
Epoch 29/80
10/10 - 2s - loss: 1.4114 - accuracy: 0.3245 - val_loss: 1.3498 - val_accuracy: 0.3235
Epoch 30/80
10/10 - 2s - loss: 1.4156 - accuracy: 0.2947 - val_loss: 1.3376 - val_accuracy: 0.3529
Epoch 31/80
10/10 - 2s - loss: 1.4324 - accuracy: 0.2649 - val_loss: 1.3146 - val_accuracy: 0.3235
Epoch 32/80
10/10 - 2s - loss: 1.4091 - accuracy: 0.3113 - val_loss: 1.3248 - val_accuracy: 0.2941
Epoch 33/80
10/10 - 2s - loss: 1.4429 - accuracy: 0.2815 - val_loss: 1.3555 - val_accuracy: 0.2353
Epoch 34/80
10/10 - 2s - loss: 1.4159 - accuracy: 0.2748 - val_loss: 1.3344 - val_accuracy: 0.3235
Epoch 35/80
10/10 - 2s - loss: 1.4275 - accuracy: 0.2715 - val_loss: 1.3465 - val_accuracy: 0.2941
Epoch 00035: early stopping
best epoch: 15  loss: 1.351325273513794  acc: 0.38235294818878174
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174]
Accuracy:0.382

Confusion matrix:
 [[1 3 5 3]
 [0 1 3 0]
 [0 1 6 1]
 [1 3 1 5]]

#####FOLDER NUMBER: 6
Epoch 1/80
10/10 - 3s - loss: 1.6547 - accuracy: 0.2616 - val_loss: 1.4794 - val_accuracy: 0.2353
Epoch 2/80
10/10 - 2s - loss: 1.6515 - accuracy: 0.2616 - val_loss: 1.3885 - val_accuracy: 0.2941
Epoch 3/80
10/10 - 2s - loss: 1.5831 - accuracy: 0.2517 - val_loss: 1.3739 - val_accuracy: 0.4118
Epoch 4/80
10/10 - 2s - loss: 1.5839 - accuracy: 0.2649 - val_loss: 1.4113 - val_accuracy: 0.2941
Epoch 5/80
10/10 - 2s - loss: 1.5951 - accuracy: 0.2815 - val_loss: 1.4490 - val_accuracy: 0.1765
Epoch 6/80
10/10 - 2s - loss: 1.5356 - accuracy: 0.3079 - val_loss: 1.3701 - val_accuracy: 0.4412
Epoch 7/80
10/10 - 2s - loss: 1.5725 - accuracy: 0.2881 - val_loss: 1.4101 - val_accuracy: 0.1471
Epoch 8/80
10/10 - 2s - loss: 1.5963 - accuracy: 0.2583 - val_loss: 1.4561 - val_accuracy: 0.1471
Epoch 9/80
10/10 - 2s - loss: 1.5239 - accuracy: 0.2914 - val_loss: 1.3634 - val_accuracy: 0.3529
Epoch 10/80
10/10 - 3s - loss: 1.5730 - accuracy: 0.2384 - val_loss: 1.3924 - val_accuracy: 0.3235
Epoch 11/80
10/10 - 2s - loss: 1.5256 - accuracy: 0.2848 - val_loss: 1.3959 - val_accuracy: 0.2353
Epoch 12/80
10/10 - 2s - loss: 1.5197 - accuracy: 0.2616 - val_loss: 1.3846 - val_accuracy: 0.3235
Epoch 13/80
10/10 - 2s - loss: 1.5334 - accuracy: 0.2517 - val_loss: 1.3872 - val_accuracy: 0.2059
Epoch 14/80
10/10 - 2s - loss: 1.4502 - accuracy: 0.2815 - val_loss: 1.4047 - val_accuracy: 0.2059
Epoch 15/80
10/10 - 2s - loss: 1.4214 - accuracy: 0.3377 - val_loss: 1.3841 - val_accuracy: 0.2647
Epoch 16/80
10/10 - 2s - loss: 1.4728 - accuracy: 0.2715 - val_loss: 1.3874 - val_accuracy: 0.3824
Epoch 17/80
10/10 - 2s - loss: 1.5110 - accuracy: 0.2517 - val_loss: 1.3813 - val_accuracy: 0.2941
Epoch 18/80
10/10 - 2s - loss: 1.4860 - accuracy: 0.2583 - val_loss: 1.3836 - val_accuracy: 0.2647
Epoch 19/80
10/10 - 2s - loss: 1.4568 - accuracy: 0.3146 - val_loss: 1.3910 - val_accuracy: 0.2647
Epoch 20/80
10/10 - 2s - loss: 1.4550 - accuracy: 0.2815 - val_loss: 1.3996 - val_accuracy: 0.2353
Epoch 21/80
10/10 - 2s - loss: 1.4535 - accuracy: 0.2781 - val_loss: 1.3801 - val_accuracy: 0.2353
Epoch 22/80
10/10 - 2s - loss: 1.4096 - accuracy: 0.2914 - val_loss: 1.3698 - val_accuracy: 0.3529
Epoch 23/80
10/10 - 2s - loss: 1.4773 - accuracy: 0.2682 - val_loss: 1.3862 - val_accuracy: 0.2353
Epoch 24/80
10/10 - 2s - loss: 1.4317 - accuracy: 0.2815 - val_loss: 1.3650 - val_accuracy: 0.3824
Epoch 25/80
10/10 - 2s - loss: 1.4712 - accuracy: 0.2583 - val_loss: 1.3701 - val_accuracy: 0.3529
Epoch 26/80
10/10 - 2s - loss: 1.4201 - accuracy: 0.2881 - val_loss: 1.3756 - val_accuracy: 0.2647
Epoch 00026: early stopping
best epoch: 6  loss: 1.370112657546997  acc: 0.44117647409439087
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794, 1.370112657546997] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174, 0.44117647409439087]
Accuracy:0.441

Confusion matrix:
 [[0 1 2 5]
 [0 5 2 2]
 [0 0 4 3]
 [0 1 3 6]]

#####FOLDER NUMBER: 7
Epoch 1/80
10/10 - 2s - loss: 1.7563 - accuracy: 0.2310 - val_loss: 1.3942 - val_accuracy: 0.3333
Epoch 2/80
10/10 - 2s - loss: 1.6524 - accuracy: 0.2772 - val_loss: 1.4571 - val_accuracy: 0.1212
Epoch 3/80
10/10 - 2s - loss: 1.5728 - accuracy: 0.2541 - val_loss: 1.4520 - val_accuracy: 0.1818
Epoch 4/80
10/10 - 2s - loss: 1.5920 - accuracy: 0.3069 - val_loss: 1.4427 - val_accuracy: 0.0606
Epoch 5/80
10/10 - 2s - loss: 1.5759 - accuracy: 0.2970 - val_loss: 1.4322 - val_accuracy: 0.1515
Epoch 6/80
10/10 - 2s - loss: 1.5922 - accuracy: 0.2640 - val_loss: 1.4283 - val_accuracy: 0.2121
Epoch 7/80
10/10 - 2s - loss: 1.5446 - accuracy: 0.2937 - val_loss: 1.4859 - val_accuracy: 0.0909
Epoch 8/80
10/10 - 1s - loss: 1.5037 - accuracy: 0.3003 - val_loss: 1.3859 - val_accuracy: 0.2727
Epoch 9/80
10/10 - 1s - loss: 1.5259 - accuracy: 0.2706 - val_loss: 1.4086 - val_accuracy: 0.2424
Epoch 10/80
10/10 - 1s - loss: 1.5197 - accuracy: 0.3135 - val_loss: 1.4019 - val_accuracy: 0.2424
Epoch 11/80
10/10 - 2s - loss: 1.5686 - accuracy: 0.2442 - val_loss: 1.3226 - val_accuracy: 0.4242
Epoch 12/80
10/10 - 2s - loss: 1.5109 - accuracy: 0.3036 - val_loss: 1.3786 - val_accuracy: 0.2727
Epoch 13/80
10/10 - 2s - loss: 1.5393 - accuracy: 0.2442 - val_loss: 1.4579 - val_accuracy: 0.2121
Epoch 14/80
10/10 - 3s - loss: 1.5369 - accuracy: 0.2805 - val_loss: 1.4203 - val_accuracy: 0.1212
Epoch 15/80
10/10 - 2s - loss: 1.4679 - accuracy: 0.3036 - val_loss: 1.3784 - val_accuracy: 0.1818
Epoch 16/80
10/10 - 2s - loss: 1.4615 - accuracy: 0.3069 - val_loss: 1.4010 - val_accuracy: 0.2424
Epoch 17/80
10/10 - 2s - loss: 1.5195 - accuracy: 0.2343 - val_loss: 1.4209 - val_accuracy: 0.1818
Epoch 18/80
10/10 - 2s - loss: 1.4627 - accuracy: 0.2673 - val_loss: 1.3879 - val_accuracy: 0.2121
Epoch 19/80
10/10 - 2s - loss: 1.4446 - accuracy: 0.3102 - val_loss: 1.4091 - val_accuracy: 0.2121
Epoch 20/80
10/10 - 2s - loss: 1.4526 - accuracy: 0.2706 - val_loss: 1.4077 - val_accuracy: 0.1515
Epoch 21/80
10/10 - 2s - loss: 1.5012 - accuracy: 0.2178 - val_loss: 1.4142 - val_accuracy: 0.1212
Epoch 22/80
10/10 - 3s - loss: 1.4701 - accuracy: 0.2772 - val_loss: 1.3449 - val_accuracy: 0.3636
Epoch 23/80
10/10 - 2s - loss: 1.4849 - accuracy: 0.2607 - val_loss: 1.4198 - val_accuracy: 0.1818
Epoch 24/80
10/10 - 2s - loss: 1.4361 - accuracy: 0.3201 - val_loss: 1.4219 - val_accuracy: 0.2424
Epoch 25/80
10/10 - 2s - loss: 1.3998 - accuracy: 0.3465 - val_loss: 1.3819 - val_accuracy: 0.2424
Epoch 26/80
10/10 - 2s - loss: 1.4424 - accuracy: 0.2739 - val_loss: 1.3827 - val_accuracy: 0.1818
Epoch 27/80
10/10 - 2s - loss: 1.4477 - accuracy: 0.2937 - val_loss: 1.4267 - val_accuracy: 0.1212
Epoch 28/80
10/10 - 2s - loss: 1.4037 - accuracy: 0.3135 - val_loss: 1.4150 - val_accuracy: 0.1818
Epoch 29/80
10/10 - 2s - loss: 1.4177 - accuracy: 0.3234 - val_loss: 1.3838 - val_accuracy: 0.2727
Epoch 30/80
10/10 - 3s - loss: 1.4285 - accuracy: 0.2904 - val_loss: 1.3840 - val_accuracy: 0.1515
Epoch 31/80
10/10 - 2s - loss: 1.4358 - accuracy: 0.2838 - val_loss: 1.4007 - val_accuracy: 0.2424
Epoch 00031: early stopping
best epoch: 11  loss: 1.322642207145691  acc: 0.42424243688583374
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794, 1.370112657546997, 1.322642207145691] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174, 0.44117647409439087, 0.42424243688583374]
Accuracy:0.424

Confusion matrix:
 [[0 0 3 0]
 [0 6 2 1]
 [0 8 6 0]
 [0 2 3 2]]

#####FOLDER NUMBER: 8
Epoch 1/80
10/10 - 3s - loss: 1.7372 - accuracy: 0.2343 - val_loss: 1.4117 - val_accuracy: 0.2727
Epoch 2/80
10/10 - 3s - loss: 1.6443 - accuracy: 0.2409 - val_loss: 1.4082 - val_accuracy: 0.3939
Epoch 3/80
10/10 - 2s - loss: 1.6457 - accuracy: 0.2706 - val_loss: 1.4670 - val_accuracy: 0.2424
Epoch 4/80
10/10 - 3s - loss: 1.7398 - accuracy: 0.2112 - val_loss: 1.3991 - val_accuracy: 0.2424
Epoch 5/80
10/10 - 3s - loss: 1.5289 - accuracy: 0.2805 - val_loss: 1.4206 - val_accuracy: 0.2727
Epoch 6/80
10/10 - 3s - loss: 1.5413 - accuracy: 0.3036 - val_loss: 1.4328 - val_accuracy: 0.3030
Epoch 7/80
10/10 - 2s - loss: 1.4809 - accuracy: 0.2838 - val_loss: 1.3509 - val_accuracy: 0.3636
Epoch 8/80
10/10 - 2s - loss: 1.5487 - accuracy: 0.3003 - val_loss: 1.3628 - val_accuracy: 0.3030
Epoch 9/80
10/10 - 3s - loss: 1.4405 - accuracy: 0.3135 - val_loss: 1.3964 - val_accuracy: 0.2727
Epoch 10/80
10/10 - 2s - loss: 1.5551 - accuracy: 0.2376 - val_loss: 1.3698 - val_accuracy: 0.2727
Epoch 11/80
10/10 - 2s - loss: 1.5660 - accuracy: 0.2673 - val_loss: 1.3909 - val_accuracy: 0.2727
Epoch 12/80
10/10 - 2s - loss: 1.4965 - accuracy: 0.3036 - val_loss: 1.4151 - val_accuracy: 0.3636
Epoch 13/80
10/10 - 2s - loss: 1.4926 - accuracy: 0.2574 - val_loss: 1.3738 - val_accuracy: 0.3636
Epoch 14/80
10/10 - 2s - loss: 1.5555 - accuracy: 0.2475 - val_loss: 1.4099 - val_accuracy: 0.3636
Epoch 15/80
10/10 - 2s - loss: 1.4527 - accuracy: 0.3201 - val_loss: 1.3987 - val_accuracy: 0.2727
Epoch 16/80
10/10 - 2s - loss: 1.4820 - accuracy: 0.2904 - val_loss: 1.3445 - val_accuracy: 0.3030
Epoch 17/80
10/10 - 2s - loss: 1.5055 - accuracy: 0.2871 - val_loss: 1.3889 - val_accuracy: 0.3333
Epoch 18/80
10/10 - 3s - loss: 1.4413 - accuracy: 0.3036 - val_loss: 1.4110 - val_accuracy: 0.3333
Epoch 19/80
10/10 - 2s - loss: 1.4418 - accuracy: 0.3267 - val_loss: 1.3870 - val_accuracy: 0.3333
Epoch 20/80
10/10 - 3s - loss: 1.4525 - accuracy: 0.2904 - val_loss: 1.4067 - val_accuracy: 0.3636
Epoch 21/80
10/10 - 2s - loss: 1.4671 - accuracy: 0.2805 - val_loss: 1.3771 - val_accuracy: 0.3636
Epoch 22/80
10/10 - 2s - loss: 1.4728 - accuracy: 0.2937 - val_loss: 1.3789 - val_accuracy: 0.3030
Epoch 00022: early stopping
best epoch: 2  loss: 1.4081681966781616  acc: 0.39393940567970276
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794, 1.370112657546997, 1.322642207145691, 1.4081681966781616] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174, 0.44117647409439087, 0.42424243688583374, 0.39393940567970276]
Accuracy:0.394

Confusion matrix:
 [[4 7 0 1]
 [0 6 0 0]
 [1 3 0 1]
 [0 7 0 3]]

#####FOLDER NUMBER: 9
Epoch 1/80
10/10 - 2s - loss: 1.7047 - accuracy: 0.2574 - val_loss: 1.4455 - val_accuracy: 0.2424
Epoch 2/80
10/10 - 2s - loss: 1.7255 - accuracy: 0.2211 - val_loss: 1.3805 - val_accuracy: 0.3333
Epoch 3/80
10/10 - 2s - loss: 1.5772 - accuracy: 0.2541 - val_loss: 1.3955 - val_accuracy: 0.3333
Epoch 4/80
10/10 - 2s - loss: 1.5627 - accuracy: 0.2772 - val_loss: 1.3714 - val_accuracy: 0.3333
Epoch 5/80
10/10 - 2s - loss: 1.6072 - accuracy: 0.2970 - val_loss: 1.3792 - val_accuracy: 0.3030
Epoch 6/80
10/10 - 2s - loss: 1.6438 - accuracy: 0.2442 - val_loss: 1.3727 - val_accuracy: 0.3030
Epoch 7/80
10/10 - 3s - loss: 1.5834 - accuracy: 0.2739 - val_loss: 1.3710 - val_accuracy: 0.3030
Epoch 8/80
10/10 - 3s - loss: 1.5586 - accuracy: 0.2904 - val_loss: 1.3451 - val_accuracy: 0.4242
Epoch 9/80
10/10 - 3s - loss: 1.5985 - accuracy: 0.2376 - val_loss: 1.3869 - val_accuracy: 0.2424
Epoch 10/80
10/10 - 3s - loss: 1.5298 - accuracy: 0.2805 - val_loss: 1.3630 - val_accuracy: 0.2727
Epoch 11/80
10/10 - 3s - loss: 1.5346 - accuracy: 0.2838 - val_loss: 1.3728 - val_accuracy: 0.3030
Epoch 12/80
10/10 - 2s - loss: 1.5188 - accuracy: 0.2541 - val_loss: 1.3197 - val_accuracy: 0.3939
Epoch 13/80
10/10 - 2s - loss: 1.4959 - accuracy: 0.2508 - val_loss: 1.3588 - val_accuracy: 0.3333
Epoch 14/80
10/10 - 2s - loss: 1.5307 - accuracy: 0.2673 - val_loss: 1.3560 - val_accuracy: 0.2424
Epoch 15/80
10/10 - 2s - loss: 1.5110 - accuracy: 0.2706 - val_loss: 1.3838 - val_accuracy: 0.2424
Epoch 16/80
10/10 - 2s - loss: 1.4791 - accuracy: 0.2574 - val_loss: 1.3934 - val_accuracy: 0.1818
Epoch 17/80
10/10 - 2s - loss: 1.4717 - accuracy: 0.2871 - val_loss: 1.3942 - val_accuracy: 0.1515
Epoch 18/80
10/10 - 2s - loss: 1.4824 - accuracy: 0.2541 - val_loss: 1.3920 - val_accuracy: 0.2727
Epoch 19/80
10/10 - 3s - loss: 1.4237 - accuracy: 0.2970 - val_loss: 1.3929 - val_accuracy: 0.2727
Epoch 20/80
10/10 - 2s - loss: 1.4488 - accuracy: 0.2838 - val_loss: 1.3576 - val_accuracy: 0.2121
Epoch 21/80
10/10 - 2s - loss: 1.4857 - accuracy: 0.2673 - val_loss: 1.3484 - val_accuracy: 0.2727
Epoch 22/80
10/10 - 3s - loss: 1.4673 - accuracy: 0.2640 - val_loss: 1.3850 - val_accuracy: 0.2121
Epoch 23/80
10/10 - 2s - loss: 1.4414 - accuracy: 0.2871 - val_loss: 1.3758 - val_accuracy: 0.2727
Epoch 24/80
10/10 - 3s - loss: 1.4951 - accuracy: 0.2475 - val_loss: 1.3417 - val_accuracy: 0.3333
Epoch 25/80
10/10 - 2s - loss: 1.4665 - accuracy: 0.2805 - val_loss: 1.3554 - val_accuracy: 0.2121
Epoch 26/80
10/10 - 3s - loss: 1.4483 - accuracy: 0.2871 - val_loss: 1.3543 - val_accuracy: 0.2727
Epoch 27/80
10/10 - 2s - loss: 1.4264 - accuracy: 0.2838 - val_loss: 1.3475 - val_accuracy: 0.1515
Epoch 28/80
10/10 - 2s - loss: 1.4324 - accuracy: 0.2772 - val_loss: 1.3669 - val_accuracy: 0.1818
Epoch 00028: early stopping
best epoch: 8  loss: 1.3450782299041748  acc: 0.42424243688583374
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794, 1.370112657546997, 1.322642207145691, 1.4081681966781616, 1.3450782299041748] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174, 0.44117647409439087, 0.42424243688583374, 0.39393940567970276, 0.42424243688583374]
Accuracy:0.424

Confusion matrix:
 [[0 3 1 6]
 [0 9 0 1]
 [0 3 1 2]
 [0 3 0 4]]

#####FOLDER NUMBER: 10
Epoch 1/80
10/10 - 2s - loss: 1.6872 - accuracy: 0.2508 - val_loss: 1.3623 - val_accuracy: 0.3939
Epoch 2/80
10/10 - 2s - loss: 1.6549 - accuracy: 0.2706 - val_loss: 1.3749 - val_accuracy: 0.3939
Epoch 3/80
10/10 - 3s - loss: 1.6506 - accuracy: 0.2310 - val_loss: 1.3672 - val_accuracy: 0.3636
Epoch 4/80
10/10 - 2s - loss: 1.4972 - accuracy: 0.3201 - val_loss: 1.3707 - val_accuracy: 0.3030
Epoch 5/80
10/10 - 2s - loss: 1.5685 - accuracy: 0.2673 - val_loss: 1.3739 - val_accuracy: 0.2727
Epoch 6/80
10/10 - 2s - loss: 1.5509 - accuracy: 0.2937 - val_loss: 1.3096 - val_accuracy: 0.4848
Epoch 7/80
10/10 - 2s - loss: 1.5270 - accuracy: 0.2772 - val_loss: 1.3483 - val_accuracy: 0.2424
Epoch 8/80
10/10 - 2s - loss: 1.5962 - accuracy: 0.2310 - val_loss: 1.3531 - val_accuracy: 0.3030
Epoch 9/80
10/10 - 2s - loss: 1.4781 - accuracy: 0.2838 - val_loss: 1.3223 - val_accuracy: 0.4545
Epoch 10/80
10/10 - 2s - loss: 1.4701 - accuracy: 0.2805 - val_loss: 1.3207 - val_accuracy: 0.4545
Epoch 11/80
10/10 - 2s - loss: 1.4971 - accuracy: 0.2772 - val_loss: 1.3510 - val_accuracy: 0.3636
Epoch 12/80
10/10 - 2s - loss: 1.4268 - accuracy: 0.3267 - val_loss: 1.3411 - val_accuracy: 0.3333
Epoch 13/80
10/10 - 2s - loss: 1.4988 - accuracy: 0.2805 - val_loss: 1.3474 - val_accuracy: 0.2727
Epoch 14/80
10/10 - 2s - loss: 1.5117 - accuracy: 0.2178 - val_loss: 1.3378 - val_accuracy: 0.3333
Epoch 15/80
10/10 - 2s - loss: 1.4548 - accuracy: 0.2970 - val_loss: 1.3349 - val_accuracy: 0.3030
Epoch 16/80
10/10 - 2s - loss: 1.4706 - accuracy: 0.2970 - val_loss: 1.3818 - val_accuracy: 0.3030
Epoch 17/80
10/10 - 2s - loss: 1.4424 - accuracy: 0.2838 - val_loss: 1.3600 - val_accuracy: 0.2727
Epoch 18/80
10/10 - 2s - loss: 1.4946 - accuracy: 0.2640 - val_loss: 1.3617 - val_accuracy: 0.3636
Epoch 19/80
10/10 - 2s - loss: 1.4922 - accuracy: 0.2310 - val_loss: 1.3482 - val_accuracy: 0.3636
Epoch 20/80
10/10 - 3s - loss: 1.4627 - accuracy: 0.3003 - val_loss: 1.3429 - val_accuracy: 0.3636
Epoch 21/80
10/10 - 2s - loss: 1.4441 - accuracy: 0.2805 - val_loss: 1.3384 - val_accuracy: 0.2727
Epoch 22/80
10/10 - 2s - loss: 1.4631 - accuracy: 0.2442 - val_loss: 1.3563 - val_accuracy: 0.3333
Epoch 23/80
10/10 - 2s - loss: 1.4686 - accuracy: 0.2442 - val_loss: 1.3535 - val_accuracy: 0.3030
Epoch 24/80
10/10 - 2s - loss: 1.3996 - accuracy: 0.3036 - val_loss: 1.3663 - val_accuracy: 0.2727
Epoch 25/80
10/10 - 2s - loss: 1.4401 - accuracy: 0.2871 - val_loss: 1.3567 - val_accuracy: 0.4848
Epoch 26/80
10/10 - 2s - loss: 1.4384 - accuracy: 0.2904 - val_loss: 1.3645 - val_accuracy: 0.2424
Epoch 00026: early stopping
best epoch: 6  loss: 1.3095992803573608  acc: 0.4848484992980957
[1.2830241918563843, 1.3276787996292114, 1.3364826440811157, 1.3272067308425903, 1.351325273513794, 1.370112657546997, 1.322642207145691, 1.4081681966781616, 1.3450782299041748, 1.3095992803573608] [0.5, 0.4117647111415863, 0.44117647409439087, 0.38235294818878174, 0.38235294818878174, 0.44117647409439087, 0.42424243688583374, 0.39393940567970276, 0.42424243688583374, 0.4848484992980957]
Accuracy:0.485

Confusion matrix:
 [[4 0 3 2]
 [2 2 3 1]
 [0 0 7 1]
 [1 0 4 3]]


 ############# AVERAGE EVALUATIONS ############

######### MEAN LOSS OVER THE 10 FOLDERS: 1.3381318211555482  ###########
######### MEAN ACCURACY OVER THE 10 FOLDERS: 0.42860963344573977  ###########
######### LOSS STANDARD DEVIATION OVER THE 10 FOLDERS: 0.03236111161289316  ###########
######### ACC STANDARD DEVIATION OVER THE 10 FOLDERS: 0.03791902980190582  ###########


 ############# FINAL AVERAGE EVALUATIONS FOR ITERATIONS ############

#### MEAN OF LOSSES MEAN OVER  2  ITERATIONS:  1.3381318211555482  MEAN OF ACC MEAN OVER  2  ITERATIONS:  0.42860963344573977  #####
####STD OF MEAN LOSS OVER  1  ITERATIONS:  0.0  ##### STD OF ACC MEAN OVER  1  ITERATIONS:  0.0  #####
#### MEAN LOSSES STANDARD DEVIATIONS OVER  2  ITERATIONS:  0.03236111161289316  MEAN ACC STANDARD DEVIATIONS OVER  2  ITERATIONS:  0.03791902980190582  #####
####STANDARD DEVIATION OF LOSS STANDARD DEVIATION OVER  1  ITERATIONS:  0.0  STANDARD DEVIATION OF ACC STANDARD DEVIATION OVER  1  ITERATIONS: 0.0 #####
####AVERAGE MAX-MIN DIFFERENCE OVER  1  ITERATIONS:  0.11764705181121826  #####
####STD.DEV MAX-MIN DIFFERENCE OVER  1  ITERATIONS:  0.0  #####

####### TIME ELAPSED:  896.7773756980896  #######
