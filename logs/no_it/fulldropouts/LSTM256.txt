2020-09-24 12:51:08.273030: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-09-24 12:51:08.273271: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-09-24 12:51:11.159057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28d70069c20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-24 12:51:11.159840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-24 12:51:11.161740: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-09-24 12:51:11.161963: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-24 12:51:11.166974: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-OVHAIFS
2020-09-24 12:51:11.167349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-OVHAIFS
WARNING:tensorflow:From C:/Users/mp95/PycharmProjects/Thesis/model/lstm_parselmouth3.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Using TensorFlow backend.
curdir: C:\Users\mp95\PycharmProjects\Thesis\model
started reading folder Sad
  0%|          | 0/84 [00:00<?, ?it/s]  7%|?         | 6/84 [00:00<00:01, 58.87it/s] 21%|???       | 18/84 [00:00<00:00, 68.09it/s] 32%|????      | 27/84 [00:00<00:00, 72.93it/s] 45%|?????     | 38/84 [00:00<00:00, 79.39it/s] 55%|??????    | 46/84 [00:00<00:00, 74.28it/s] 64%|???????   | 54/84 [00:00<00:00, 75.50it/s] 81%|????????  | 68/84 [00:00<00:00, 86.80it/s] 93%|??????????| 78/84 [00:00<00:00, 74.13it/s]100%|??????????| 84/84 [00:01<00:00, 83.74it/s]
ended reading folder Sad
started reading folder Happy
  0%|          | 0/84 [00:00<?, ?it/s] 17%|??        | 14/84 [00:00<00:00, 130.95it/s] 27%|???       | 23/84 [00:00<00:00, 113.52it/s] 37%|????      | 31/84 [00:00<00:00, 98.28it/s]  52%|??????    | 44/84 [00:00<00:00, 101.59it/s] 69%|???????   | 58/84 [00:00<00:00, 108.16it/s] 81%|????????  | 68/84 [00:00<00:00, 101.74it/s] 93%|??????????| 78/84 [00:00<00:00, 90.04it/s] 100%|??????????| 84/84 [00:00<00:00, 98.44it/s]
ended reading folder Happy
started reading folder Angry
  0%|          | 0/84 [00:00<?, ?it/s] 14%|??        | 12/84 [00:00<00:00, 117.75it/s] 20%|??        | 17/84 [00:00<00:00, 79.75it/s]  30%|???       | 25/84 [00:00<00:00, 77.27it/s] 44%|?????     | 37/84 [00:00<00:00, 85.42it/s] 55%|??????    | 46/84 [00:00<00:00, 85.77it/s] 64%|???????   | 54/84 [00:00<00:00, 83.45it/s] 75%|????????  | 63/84 [00:00<00:00, 82.52it/s] 88%|????????? | 74/84 [00:00<00:00, 87.94it/s]100%|??????????| 84/84 [00:00<00:00, 88.13it/s]100%|??????????| 84/84 [00:00<00:00, 87.02it/s]
ended reading folder Angry
started reading folder Neutral
  0%|          | 0/84 [00:00<?, ?it/s] 11%|?         | 9/84 [00:00<00:00, 84.98it/s] 23%|???       | 19/84 [00:00<00:00, 86.70it/s] 33%|????      | 28/84 [00:00<00:00, 85.88it/s] 44%|?????     | 37/84 [00:00<00:00, 84.88it/s] 52%|??????    | 44/84 [00:00<00:00, 72.84it/s] 68%|???????   | 57/84 [00:00<00:00, 81.10it/s] 77%|????????  | 65/84 [00:00<00:00, 76.61it/s] 87%|????????? | 73/84 [00:00<00:00, 71.20it/s]100%|??????????| 84/84 [00:01<00:00, 78.79it/s]100%|??????????| 84/84 [00:01<00:00, 81.45it/s]
ended reading folder Neutral

EXECUTION PARAMETERS: {NUMBER OF FOLDERS:  5 }-{NUMBER OF EPOCHS:  80 }-{NUMBER OF ROUTINE ITERATIONS:  1 }-{BATCH SIZE :  32 }-{SIGNAL MODE:  fp }-{AUGMENT: Sad }-{FEATURES:  mfcc }-{EMOTIONS: ('Sad', 'Happy', 'Angry', 'Neutral') }

####ITERATION NUMBER:  1

#####FOLDER NUMBER: 1
Starting LSTM
None
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 44, 13)            0         
_________________________________________________________________
lstm (LSTM)                  (None, 256)               276480    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 4)                 1028      
=================================================================
Total params: 277,508
Trainable params: 277,508
Non-trainable params: 0
_________________________________________________________________
Epoch 1/80
9/9 - 3s - loss: 1.3550 - accuracy: 0.3246 - val_loss: 1.0811 - val_accuracy: 0.5000
Epoch 2/80
9/9 - 1s - loss: 1.0578 - accuracy: 0.5149 - val_loss: 1.0365 - val_accuracy: 0.4853
Epoch 3/80
9/9 - 1s - loss: 1.0178 - accuracy: 0.5784 - val_loss: 1.0311 - val_accuracy: 0.5000
Epoch 4/80
9/9 - 1s - loss: 0.9293 - accuracy: 0.5821 - val_loss: 0.9927 - val_accuracy: 0.5294
Epoch 5/80
9/9 - 1s - loss: 0.8155 - accuracy: 0.6567 - val_loss: 0.9694 - val_accuracy: 0.5735
Epoch 6/80
9/9 - 1s - loss: 0.7440 - accuracy: 0.6604 - val_loss: 0.8698 - val_accuracy: 0.6471
Epoch 7/80
9/9 - 1s - loss: 0.7414 - accuracy: 0.6754 - val_loss: 0.8311 - val_accuracy: 0.6618
Epoch 8/80
9/9 - 1s - loss: 0.6323 - accuracy: 0.7276 - val_loss: 0.8208 - val_accuracy: 0.6765
Epoch 9/80
9/9 - 1s - loss: 0.5302 - accuracy: 0.7985 - val_loss: 0.9016 - val_accuracy: 0.5735
Epoch 10/80
9/9 - 1s - loss: 0.4823 - accuracy: 0.8134 - val_loss: 0.8304 - val_accuracy: 0.6471
Epoch 11/80
9/9 - 1s - loss: 0.4575 - accuracy: 0.8022 - val_loss: 1.0236 - val_accuracy: 0.6471
Epoch 12/80
9/9 - 1s - loss: 0.4692 - accuracy: 0.8134 - val_loss: 0.7096 - val_accuracy: 0.7353
Epoch 13/80
9/9 - 1s - loss: 0.4041 - accuracy: 0.8433 - val_loss: 1.0608 - val_accuracy: 0.5588
Epoch 14/80
9/9 - 1s - loss: 0.3395 - accuracy: 0.8731 - val_loss: 0.7746 - val_accuracy: 0.7059
Epoch 15/80
9/9 - 1s - loss: 0.3198 - accuracy: 0.8731 - val_loss: 0.8206 - val_accuracy: 0.6765
Epoch 16/80
9/9 - 1s - loss: 0.2446 - accuracy: 0.9403 - val_loss: 1.0154 - val_accuracy: 0.6029
Epoch 17/80
9/9 - 1s - loss: 0.2184 - accuracy: 0.9328 - val_loss: 0.7494 - val_accuracy: 0.7794
Epoch 18/80
9/9 - 1s - loss: 0.1660 - accuracy: 0.9552 - val_loss: 1.0848 - val_accuracy: 0.6765
Epoch 19/80
9/9 - 1s - loss: 0.1606 - accuracy: 0.9403 - val_loss: 0.9900 - val_accuracy: 0.6912
Epoch 20/80
9/9 - 1s - loss: 0.1542 - accuracy: 0.9478 - val_loss: 1.1933 - val_accuracy: 0.6471
Epoch 21/80
9/9 - 1s - loss: 0.1946 - accuracy: 0.9216 - val_loss: 0.9981 - val_accuracy: 0.6618
Epoch 22/80
9/9 - 2s - loss: 0.1515 - accuracy: 0.9552 - val_loss: 0.8755 - val_accuracy: 0.6912
Epoch 23/80
9/9 - 2s - loss: 0.0766 - accuracy: 0.9925 - val_loss: 0.9376 - val_accuracy: 0.6912
Epoch 24/80
9/9 - 1s - loss: 0.0705 - accuracy: 0.9888 - val_loss: 1.0291 - val_accuracy: 0.6912
Epoch 25/80
9/9 - 1s - loss: 0.0654 - accuracy: 0.9813 - val_loss: 0.9031 - val_accuracy: 0.7059
Epoch 26/80
9/9 - 1s - loss: 0.0500 - accuracy: 0.9963 - val_loss: 1.0021 - val_accuracy: 0.6471
Epoch 27/80
9/9 - 1s - loss: 0.0497 - accuracy: 0.9813 - val_loss: 1.1199 - val_accuracy: 0.6912
Epoch 28/80
9/9 - 1s - loss: 0.1006 - accuracy: 0.9552 - val_loss: 1.0401 - val_accuracy: 0.7059
Epoch 29/80
9/9 - 1s - loss: 0.0779 - accuracy: 0.9813 - val_loss: 1.1385 - val_accuracy: 0.6765
Epoch 30/80
9/9 - 1s - loss: 0.0784 - accuracy: 0.9776 - val_loss: 1.0167 - val_accuracy: 0.6912
Epoch 31/80
9/9 - 1s - loss: 0.0452 - accuracy: 0.9925 - val_loss: 1.1795 - val_accuracy: 0.6618
Epoch 32/80
9/9 - 1s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.7059
Epoch 33/80
9/9 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.6765
Epoch 34/80
9/9 - 1s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.6765
Epoch 35/80
9/9 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.6765
Epoch 36/80
9/9 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.6765
Epoch 37/80
9/9 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4233 - val_accuracy: 0.6471
Epoch 00037: early stopping
best epoch: 17  loss: 0.7493755221366882  acc: 0.779411792755127
[0.7493755221366882] [0.779411792755127]
Accuracy:0.779

Confusion matrix:
 [[ 8  0  0  4]
 [ 0 20  2  2]
 [ 2  2 12  0]
 [ 1  1  1 13]]

#####FOLDER NUMBER: 2
Epoch 1/80
9/9 - 1s - loss: 1.4703 - accuracy: 0.2825 - val_loss: 1.2102 - val_accuracy: 0.3433
Epoch 2/80
9/9 - 1s - loss: 1.1918 - accuracy: 0.4275 - val_loss: 1.0435 - val_accuracy: 0.4627
Epoch 3/80
9/9 - 1s - loss: 1.0039 - accuracy: 0.5539 - val_loss: 0.9771 - val_accuracy: 0.5224
Epoch 4/80
9/9 - 1s - loss: 0.9496 - accuracy: 0.5688 - val_loss: 0.9801 - val_accuracy: 0.4925
Epoch 5/80
9/9 - 1s - loss: 0.9670 - accuracy: 0.5428 - val_loss: 0.9427 - val_accuracy: 0.5970
Epoch 6/80
9/9 - 1s - loss: 0.8761 - accuracy: 0.6171 - val_loss: 0.8700 - val_accuracy: 0.5970
Epoch 7/80
9/9 - 1s - loss: 0.7516 - accuracy: 0.6877 - val_loss: 0.8940 - val_accuracy: 0.6418
Epoch 8/80
9/9 - 1s - loss: 0.6729 - accuracy: 0.7398 - val_loss: 0.8691 - val_accuracy: 0.5821
Epoch 9/80
9/9 - 1s - loss: 0.6660 - accuracy: 0.7323 - val_loss: 0.8491 - val_accuracy: 0.6567
Epoch 10/80
9/9 - 1s - loss: 0.5807 - accuracy: 0.7807 - val_loss: 0.8266 - val_accuracy: 0.6269
Epoch 11/80
9/9 - 1s - loss: 0.5039 - accuracy: 0.8216 - val_loss: 0.8844 - val_accuracy: 0.7015
Epoch 12/80
9/9 - 1s - loss: 0.5448 - accuracy: 0.7955 - val_loss: 0.9880 - val_accuracy: 0.5821
Epoch 13/80
9/9 - 1s - loss: 0.4411 - accuracy: 0.8439 - val_loss: 0.8805 - val_accuracy: 0.6119
Epoch 14/80
9/9 - 1s - loss: 0.3332 - accuracy: 0.9033 - val_loss: 0.9256 - val_accuracy: 0.6418
Epoch 15/80
9/9 - 1s - loss: 0.3258 - accuracy: 0.8810 - val_loss: 0.8684 - val_accuracy: 0.6866
Epoch 16/80
9/9 - 1s - loss: 0.2808 - accuracy: 0.8959 - val_loss: 0.9827 - val_accuracy: 0.5970
Epoch 17/80
9/9 - 1s - loss: 0.2614 - accuracy: 0.9108 - val_loss: 1.0127 - val_accuracy: 0.5970
Epoch 18/80
9/9 - 1s - loss: 0.4441 - accuracy: 0.8178 - val_loss: 1.0696 - val_accuracy: 0.5970
Epoch 19/80
9/9 - 1s - loss: 0.2717 - accuracy: 0.8996 - val_loss: 0.8433 - val_accuracy: 0.6269
Epoch 20/80
9/9 - 1s - loss: 0.2398 - accuracy: 0.9480 - val_loss: 1.0664 - val_accuracy: 0.6269
Epoch 21/80
9/9 - 1s - loss: 0.2066 - accuracy: 0.9257 - val_loss: 1.0422 - val_accuracy: 0.6567
Epoch 22/80
9/9 - 1s - loss: 0.1468 - accuracy: 0.9591 - val_loss: 1.0436 - val_accuracy: 0.6716
Epoch 23/80
9/9 - 1s - loss: 0.1332 - accuracy: 0.9480 - val_loss: 1.1941 - val_accuracy: 0.6269
Epoch 24/80
9/9 - 1s - loss: 0.1166 - accuracy: 0.9777 - val_loss: 1.2346 - val_accuracy: 0.5522
Epoch 25/80
9/9 - 1s - loss: 0.1147 - accuracy: 0.9665 - val_loss: 1.2525 - val_accuracy: 0.5970
Epoch 26/80
9/9 - 1s - loss: 0.0889 - accuracy: 0.9777 - val_loss: 1.3853 - val_accuracy: 0.5522
Epoch 27/80
9/9 - 1s - loss: 0.1117 - accuracy: 0.9665 - val_loss: 1.1470 - val_accuracy: 0.6418
Epoch 28/80
9/9 - 1s - loss: 0.0666 - accuracy: 0.9888 - val_loss: 1.2269 - val_accuracy: 0.6418
Epoch 29/80
9/9 - 1s - loss: 0.0535 - accuracy: 0.9963 - val_loss: 1.2075 - val_accuracy: 0.5821
Epoch 30/80
9/9 - 1s - loss: 0.1114 - accuracy: 0.9665 - val_loss: 1.1704 - val_accuracy: 0.5970
Epoch 31/80
9/9 - 1s - loss: 0.0837 - accuracy: 0.9777 - val_loss: 1.4636 - val_accuracy: 0.5522
Epoch 00031: early stopping
best epoch: 11  loss: 0.8843654990196228  acc: 0.7014925479888916
[0.7493755221366882, 0.8843654990196228] [0.779411792755127, 0.7014925479888916]
Accuracy:0.701

Confusion matrix:
 [[15  0  0  2]
 [ 1 10  3  0]
 [ 0  4 14  2]
 [ 8  0  0  8]]

#####FOLDER NUMBER: 3
Epoch 1/80
9/9 - 1s - loss: 1.4904 - accuracy: 0.2788 - val_loss: 1.3056 - val_accuracy: 0.3134
Epoch 2/80
9/9 - 1s - loss: 1.1974 - accuracy: 0.4572 - val_loss: 1.1150 - val_accuracy: 0.4179
Epoch 3/80
9/9 - 1s - loss: 1.0837 - accuracy: 0.5093 - val_loss: 1.1422 - val_accuracy: 0.4328
Epoch 4/80
9/9 - 1s - loss: 0.9253 - accuracy: 0.6208 - val_loss: 1.0461 - val_accuracy: 0.4925
Epoch 5/80
9/9 - 1s - loss: 0.9312 - accuracy: 0.6059 - val_loss: 1.1172 - val_accuracy: 0.4627
Epoch 6/80
9/9 - 1s - loss: 0.8326 - accuracy: 0.6357 - val_loss: 0.9863 - val_accuracy: 0.5075
Epoch 7/80
9/9 - 1s - loss: 0.7663 - accuracy: 0.6989 - val_loss: 0.9872 - val_accuracy: 0.5373
Epoch 8/80
9/9 - 1s - loss: 0.7171 - accuracy: 0.7361 - val_loss: 0.9669 - val_accuracy: 0.5224
Epoch 9/80
9/9 - 1s - loss: 0.7262 - accuracy: 0.6989 - val_loss: 0.9988 - val_accuracy: 0.5522
Epoch 10/80
9/9 - 1s - loss: 0.6612 - accuracy: 0.7398 - val_loss: 0.9051 - val_accuracy: 0.5821
Epoch 11/80
9/9 - 1s - loss: 0.5890 - accuracy: 0.7546 - val_loss: 1.1673 - val_accuracy: 0.3881
Epoch 12/80
9/9 - 1s - loss: 0.5912 - accuracy: 0.7584 - val_loss: 0.9183 - val_accuracy: 0.5672
Epoch 13/80
9/9 - 1s - loss: 0.5468 - accuracy: 0.7955 - val_loss: 0.9820 - val_accuracy: 0.5373
Epoch 14/80
9/9 - 1s - loss: 0.4369 - accuracy: 0.8401 - val_loss: 0.8852 - val_accuracy: 0.6418
Epoch 15/80
9/9 - 1s - loss: 0.3716 - accuracy: 0.8736 - val_loss: 0.7682 - val_accuracy: 0.6866
Epoch 16/80
9/9 - 1s - loss: 0.3496 - accuracy: 0.8848 - val_loss: 0.8049 - val_accuracy: 0.6269
Epoch 17/80
9/9 - 1s - loss: 0.3018 - accuracy: 0.8885 - val_loss: 0.7183 - val_accuracy: 0.6567
Epoch 18/80
9/9 - 1s - loss: 0.2536 - accuracy: 0.9033 - val_loss: 0.6999 - val_accuracy: 0.6716
Epoch 19/80
9/9 - 1s - loss: 0.2348 - accuracy: 0.9033 - val_loss: 0.7977 - val_accuracy: 0.6567
Epoch 20/80
9/9 - 1s - loss: 0.1859 - accuracy: 0.9331 - val_loss: 0.9532 - val_accuracy: 0.6418
Epoch 21/80
9/9 - 1s - loss: 0.1709 - accuracy: 0.9405 - val_loss: 0.8003 - val_accuracy: 0.6716
Epoch 22/80
9/9 - 1s - loss: 0.1126 - accuracy: 0.9777 - val_loss: 0.9220 - val_accuracy: 0.6716
Epoch 23/80
9/9 - 1s - loss: 0.1597 - accuracy: 0.9517 - val_loss: 1.0513 - val_accuracy: 0.6567
Epoch 24/80
9/9 - 1s - loss: 0.3186 - accuracy: 0.8922 - val_loss: 0.8961 - val_accuracy: 0.6269
Epoch 25/80
9/9 - 1s - loss: 0.1969 - accuracy: 0.9405 - val_loss: 0.7245 - val_accuracy: 0.7015
Epoch 26/80
9/9 - 1s - loss: 0.1439 - accuracy: 0.9628 - val_loss: 0.9255 - val_accuracy: 0.7015
Epoch 27/80
9/9 - 1s - loss: 0.0804 - accuracy: 0.9888 - val_loss: 0.8366 - val_accuracy: 0.6866
Epoch 28/80
9/9 - 1s - loss: 0.0863 - accuracy: 0.9851 - val_loss: 0.9337 - val_accuracy: 0.6418
Epoch 29/80
9/9 - 1s - loss: 0.0602 - accuracy: 0.9851 - val_loss: 1.0104 - val_accuracy: 0.7015
Epoch 30/80
9/9 - 2s - loss: 0.0430 - accuracy: 0.9926 - val_loss: 0.9055 - val_accuracy: 0.6866
Epoch 31/80
9/9 - 1s - loss: 0.0454 - accuracy: 0.9926 - val_loss: 1.1911 - val_accuracy: 0.6119
Epoch 32/80
9/9 - 1s - loss: 0.0329 - accuracy: 0.9963 - val_loss: 0.9350 - val_accuracy: 0.7164
Epoch 33/80
9/9 - 1s - loss: 0.0326 - accuracy: 0.9926 - val_loss: 1.2214 - val_accuracy: 0.6716
Epoch 34/80
9/9 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.6716
Epoch 35/80
9/9 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.7164
Epoch 36/80
9/9 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.1308 - val_accuracy: 0.6567
Epoch 37/80
9/9 - 1s - loss: 0.0850 - accuracy: 0.9851 - val_loss: 1.2178 - val_accuracy: 0.6866
Epoch 38/80
9/9 - 1s - loss: 0.2019 - accuracy: 0.9219 - val_loss: 1.1268 - val_accuracy: 0.6119
Epoch 39/80
9/9 - 1s - loss: 0.0843 - accuracy: 0.9777 - val_loss: 0.9375 - val_accuracy: 0.6866
Epoch 40/80
9/9 - 1s - loss: 0.0598 - accuracy: 0.9851 - val_loss: 1.1804 - val_accuracy: 0.6418
Epoch 41/80
9/9 - 1s - loss: 0.1596 - accuracy: 0.9405 - val_loss: 1.5129 - val_accuracy: 0.5821
Epoch 42/80
9/9 - 1s - loss: 0.1319 - accuracy: 0.9517 - val_loss: 1.0034 - val_accuracy: 0.6567
Epoch 43/80
9/9 - 1s - loss: 0.1363 - accuracy: 0.9517 - val_loss: 1.1507 - val_accuracy: 0.6119
Epoch 44/80
9/9 - 1s - loss: 0.1257 - accuracy: 0.9591 - val_loss: 1.0650 - val_accuracy: 0.5970
Epoch 45/80
9/9 - 1s - loss: 0.0610 - accuracy: 0.9888 - val_loss: 0.8605 - val_accuracy: 0.6119
Epoch 46/80
9/9 - 1s - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.9359 - val_accuracy: 0.6866
Epoch 47/80
9/9 - 1s - loss: 0.0372 - accuracy: 0.9963 - val_loss: 0.9200 - val_accuracy: 0.7015
Epoch 48/80
9/9 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.6567
Epoch 49/80
9/9 - 1s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.6567
Epoch 50/80
9/9 - 1s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.6716
Epoch 51/80
9/9 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0395 - val_accuracy: 0.6716
Epoch 52/80
9/9 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.6866
Epoch 00052: early stopping
best epoch: 32  loss: 0.9349795579910278  acc: 0.7164179086685181
[0.7493755221366882, 0.8843654990196228, 0.9349795579910278] [0.779411792755127, 0.7014925479888916, 0.7164179086685181]
Accuracy:0.716

Confusion matrix:
 [[19  0  0  2]
 [ 0  6  4  2]
 [ 0  5 10  0]
 [ 2  2  2 13]]

#####FOLDER NUMBER: 4
Epoch 1/80
9/9 - 1s - loss: 1.4652 - accuracy: 0.2788 - val_loss: 1.2788 - val_accuracy: 0.4030
Epoch 2/80
9/9 - 1s - loss: 1.1898 - accuracy: 0.4461 - val_loss: 1.1671 - val_accuracy: 0.5075
Epoch 3/80
9/9 - 1s - loss: 1.0385 - accuracy: 0.5204 - val_loss: 1.1193 - val_accuracy: 0.4478
Epoch 4/80
9/9 - 1s - loss: 1.0259 - accuracy: 0.5390 - val_loss: 1.0677 - val_accuracy: 0.5075
Epoch 5/80
9/9 - 1s - loss: 0.9071 - accuracy: 0.5502 - val_loss: 1.0459 - val_accuracy: 0.5821
Epoch 6/80
9/9 - 1s - loss: 0.8472 - accuracy: 0.6357 - val_loss: 1.0322 - val_accuracy: 0.5821
Epoch 7/80
9/9 - 1s - loss: 0.7856 - accuracy: 0.6394 - val_loss: 0.9681 - val_accuracy: 0.5522
Epoch 8/80
9/9 - 1s - loss: 0.8007 - accuracy: 0.6245 - val_loss: 1.0087 - val_accuracy: 0.5821
Epoch 9/80
9/9 - 1s - loss: 0.7141 - accuracy: 0.6952 - val_loss: 0.9870 - val_accuracy: 0.6567
Epoch 10/80
9/9 - 1s - loss: 0.6051 - accuracy: 0.7621 - val_loss: 0.9155 - val_accuracy: 0.5821
Epoch 11/80
9/9 - 1s - loss: 0.5116 - accuracy: 0.7993 - val_loss: 0.9340 - val_accuracy: 0.6418
Epoch 12/80
9/9 - 1s - loss: 0.4905 - accuracy: 0.8141 - val_loss: 1.0687 - val_accuracy: 0.6269
Epoch 13/80
9/9 - 1s - loss: 0.5126 - accuracy: 0.7844 - val_loss: 0.9176 - val_accuracy: 0.6418
Epoch 14/80
9/9 - 1s - loss: 0.4720 - accuracy: 0.7844 - val_loss: 0.9866 - val_accuracy: 0.6119
Epoch 15/80
9/9 - 1s - loss: 0.4649 - accuracy: 0.8327 - val_loss: 0.8664 - val_accuracy: 0.6716
Epoch 16/80
9/9 - 1s - loss: 0.3370 - accuracy: 0.8662 - val_loss: 0.8639 - val_accuracy: 0.6418
Epoch 17/80
9/9 - 1s - loss: 0.3190 - accuracy: 0.8550 - val_loss: 0.8733 - val_accuracy: 0.6866
Epoch 18/80
9/9 - 1s - loss: 0.2322 - accuracy: 0.9182 - val_loss: 0.9877 - val_accuracy: 0.6716
Epoch 19/80
9/9 - 1s - loss: 0.2106 - accuracy: 0.9145 - val_loss: 1.2361 - val_accuracy: 0.6119
Epoch 20/80
9/9 - 1s - loss: 0.2511 - accuracy: 0.9071 - val_loss: 1.1915 - val_accuracy: 0.6716
Epoch 21/80
9/9 - 1s - loss: 0.1822 - accuracy: 0.9331 - val_loss: 1.1729 - val_accuracy: 0.6567
Epoch 22/80
9/9 - 1s - loss: 0.1491 - accuracy: 0.9517 - val_loss: 1.2486 - val_accuracy: 0.6567
Epoch 23/80
9/9 - 1s - loss: 0.1458 - accuracy: 0.9517 - val_loss: 1.2037 - val_accuracy: 0.6716
Epoch 24/80
9/9 - 1s - loss: 0.1528 - accuracy: 0.9517 - val_loss: 1.4990 - val_accuracy: 0.5821
Epoch 25/80
9/9 - 1s - loss: 0.1768 - accuracy: 0.9294 - val_loss: 1.5760 - val_accuracy: 0.6119
Epoch 26/80
9/9 - 1s - loss: 0.3061 - accuracy: 0.8810 - val_loss: 1.1319 - val_accuracy: 0.6567
Epoch 27/80
9/9 - 1s - loss: 0.2299 - accuracy: 0.9108 - val_loss: 1.0837 - val_accuracy: 0.6866
Epoch 28/80
9/9 - 1s - loss: 0.1629 - accuracy: 0.9554 - val_loss: 0.9062 - val_accuracy: 0.7015
Epoch 29/80
9/9 - 1s - loss: 0.0875 - accuracy: 0.9888 - val_loss: 1.0332 - val_accuracy: 0.7164
Epoch 30/80
9/9 - 1s - loss: 0.0883 - accuracy: 0.9814 - val_loss: 1.2132 - val_accuracy: 0.7164
Epoch 31/80
9/9 - 1s - loss: 0.0479 - accuracy: 0.9963 - val_loss: 1.3233 - val_accuracy: 0.7015
Epoch 32/80
9/9 - 1s - loss: 0.0535 - accuracy: 0.9851 - val_loss: 1.4424 - val_accuracy: 0.7015
Epoch 33/80
9/9 - 1s - loss: 0.1074 - accuracy: 0.9740 - val_loss: 1.3046 - val_accuracy: 0.6716
Epoch 34/80
9/9 - 1s - loss: 0.0644 - accuracy: 0.9888 - val_loss: 1.3094 - val_accuracy: 0.6269
Epoch 35/80
9/9 - 1s - loss: 0.0400 - accuracy: 0.9926 - val_loss: 1.2522 - val_accuracy: 0.6866
Epoch 36/80
9/9 - 1s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.2370 - val_accuracy: 0.6716
Epoch 37/80
9/9 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.2791 - val_accuracy: 0.7313
Epoch 38/80
9/9 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.4356 - val_accuracy: 0.6716
Epoch 39/80
9/9 - 1s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.5036 - val_accuracy: 0.6716
Epoch 40/80
9/9 - 1s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.7015
Epoch 41/80
9/9 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.7313
Epoch 42/80
9/9 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5568 - val_accuracy: 0.7164
Epoch 43/80
9/9 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.7015
Epoch 44/80
9/9 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6506 - val_accuracy: 0.6866
Epoch 45/80
9/9 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6824 - val_accuracy: 0.7015
Epoch 46/80
9/9 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.7312 - val_accuracy: 0.7015
Epoch 47/80
9/9 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.7948 - val_accuracy: 0.6866
Epoch 48/80
9/9 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.6866
Epoch 49/80
9/9 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.8350 - val_accuracy: 0.6716
Epoch 50/80
9/9 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.8271 - val_accuracy: 0.7015
Epoch 51/80
9/9 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8520 - val_accuracy: 0.6866
Epoch 52/80
9/9 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.6866
Epoch 53/80
9/9 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9297 - val_accuracy: 0.6866
Epoch 54/80
9/9 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.9752 - val_accuracy: 0.6866
Epoch 55/80
9/9 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.0089 - val_accuracy: 0.6866
Epoch 56/80
9/9 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0011 - val_accuracy: 0.6866
Epoch 57/80
9/9 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.6866
Epoch 00057: early stopping
best epoch: 37  loss: 1.2791085243225098  acc: 0.7313432693481445
[0.7493755221366882, 0.8843654990196228, 0.9349795579910278, 1.2791085243225098] [0.779411792755127, 0.7014925479888916, 0.7164179086685181, 0.7313432693481445]
Accuracy:0.731

Confusion matrix:
 [[13  1  0  1]
 [ 2 11  1  2]
 [ 0  3 13  2]
 [ 3  3  0 12]]

#####FOLDER NUMBER: 5
Epoch 1/80
9/9 - 1s - loss: 1.4682 - accuracy: 0.2862 - val_loss: 1.2055 - val_accuracy: 0.5224
Epoch 2/80
9/9 - 1s - loss: 1.1770 - accuracy: 0.4238 - val_loss: 1.1489 - val_accuracy: 0.4328
Epoch 3/80
9/9 - 1s - loss: 1.0567 - accuracy: 0.4796 - val_loss: 1.0676 - val_accuracy: 0.5821
Epoch 4/80
9/9 - 1s - loss: 0.9395 - accuracy: 0.5874 - val_loss: 1.0889 - val_accuracy: 0.4627
Epoch 5/80
9/9 - 1s - loss: 0.9521 - accuracy: 0.5465 - val_loss: 1.0073 - val_accuracy: 0.5672
Epoch 6/80
9/9 - 1s - loss: 0.9092 - accuracy: 0.5948 - val_loss: 0.9535 - val_accuracy: 0.5821
Epoch 7/80
9/9 - 1s - loss: 0.8281 - accuracy: 0.6171 - val_loss: 0.9242 - val_accuracy: 0.6269
Epoch 8/80
9/9 - 1s - loss: 0.7887 - accuracy: 0.6394 - val_loss: 0.9031 - val_accuracy: 0.6418
Epoch 9/80
9/9 - 1s - loss: 0.7349 - accuracy: 0.6617 - val_loss: 0.8311 - val_accuracy: 0.6119
Epoch 10/80
9/9 - 1s - loss: 0.6787 - accuracy: 0.7249 - val_loss: 0.8197 - val_accuracy: 0.6418
Epoch 11/80
9/9 - 1s - loss: 0.5895 - accuracy: 0.7658 - val_loss: 0.8903 - val_accuracy: 0.5821
Epoch 12/80
9/9 - 1s - loss: 0.5564 - accuracy: 0.8067 - val_loss: 0.8343 - val_accuracy: 0.6567
Epoch 13/80
9/9 - 1s - loss: 0.5060 - accuracy: 0.8104 - val_loss: 0.7177 - val_accuracy: 0.6716
Epoch 14/80
9/9 - 1s - loss: 0.4388 - accuracy: 0.8178 - val_loss: 0.6689 - val_accuracy: 0.7164
Epoch 15/80
9/9 - 1s - loss: 0.4274 - accuracy: 0.8178 - val_loss: 0.6939 - val_accuracy: 0.6716
Epoch 16/80
9/9 - 1s - loss: 0.3574 - accuracy: 0.8736 - val_loss: 0.7457 - val_accuracy: 0.6567
Epoch 17/80
9/9 - 1s - loss: 0.3001 - accuracy: 0.8922 - val_loss: 0.6354 - val_accuracy: 0.7313
Epoch 18/80
9/9 - 1s - loss: 0.2274 - accuracy: 0.9219 - val_loss: 0.6067 - val_accuracy: 0.7612
Epoch 19/80
9/9 - 1s - loss: 0.2445 - accuracy: 0.9108 - val_loss: 0.8484 - val_accuracy: 0.6866
Epoch 20/80
9/9 - 1s - loss: 0.2175 - accuracy: 0.9331 - val_loss: 0.8396 - val_accuracy: 0.6866
Epoch 21/80
9/9 - 1s - loss: 0.2376 - accuracy: 0.9145 - val_loss: 0.7034 - val_accuracy: 0.7463
Epoch 22/80
9/9 - 1s - loss: 0.2194 - accuracy: 0.9331 - val_loss: 0.9406 - val_accuracy: 0.7015
Epoch 23/80
9/9 - 1s - loss: 0.2376 - accuracy: 0.9033 - val_loss: 1.1371 - val_accuracy: 0.6119
Epoch 24/80
9/9 - 1s - loss: 0.3905 - accuracy: 0.8513 - val_loss: 0.9715 - val_accuracy: 0.5821
Epoch 25/80
9/9 - 1s - loss: 0.4017 - accuracy: 0.8104 - val_loss: 0.8165 - val_accuracy: 0.6866
Epoch 26/80
9/9 - 1s - loss: 0.2944 - accuracy: 0.8959 - val_loss: 0.9446 - val_accuracy: 0.6418
Epoch 27/80
9/9 - 1s - loss: 0.2039 - accuracy: 0.9368 - val_loss: 0.8781 - val_accuracy: 0.6567
Epoch 28/80
9/9 - 1s - loss: 0.1490 - accuracy: 0.9628 - val_loss: 0.7135 - val_accuracy: 0.7612
Epoch 29/80
9/9 - 1s - loss: 0.0836 - accuracy: 0.9851 - val_loss: 0.8971 - val_accuracy: 0.6716
Epoch 30/80
9/9 - 1s - loss: 0.0688 - accuracy: 0.9888 - val_loss: 0.8274 - val_accuracy: 0.6716
Epoch 31/80
9/9 - 1s - loss: 0.0563 - accuracy: 0.9851 - val_loss: 0.8795 - val_accuracy: 0.7313
Epoch 32/80
9/9 - 1s - loss: 0.0366 - accuracy: 0.9963 - val_loss: 0.9078 - val_accuracy: 0.7313
Epoch 33/80
9/9 - 1s - loss: 0.0301 - accuracy: 0.9963 - val_loss: 0.9636 - val_accuracy: 0.7463
Epoch 34/80
9/9 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.7015
Epoch 35/80
9/9 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7164
Epoch 36/80
9/9 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.7313
Epoch 37/80
9/9 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.7164
Epoch 38/80
9/9 - 1s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.7313
Epoch 00038: early stopping
best epoch: 18  loss: 0.6066909432411194  acc: 0.7611940503120422
[0.7493755221366882, 0.8843654990196228, 0.9349795579910278, 1.2791085243225098, 0.6066909432411194] [0.779411792755127, 0.7014925479888916, 0.7164179086685181, 0.7313432693481445, 0.7611940503120422]
Accuracy:0.761

Confusion matrix:
 [[18  0  0  1]
 [ 1 15  0  2]
 [ 2  2 10  1]
 [ 4  2  1  8]]


 ############# AVERAGE EVALUATIONS ############

######### MEAN LOSS OVER THE 5 FOLDERS: 0.8909040093421936  ###########
######### MEAN ACCURACY OVER THE 5 FOLDERS: 0.7379719138145446  ###########
######### LOSS STANDARD DEVIATION OVER THE 5 FOLDERS: 0.22516462030713844  ###########
######### ACC STANDARD DEVIATION OVER THE 5 FOLDERS: 0.028620934249102448  ###########

####MEAN LOSSES OF THE FIRST  1  ITERATIONS:  [0.8909040093421936]  MEAN ACC OF THE FIRST  1  ITERATIONS:  [0.7379719138145446]  #####
####LOSSES STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  ACC STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  #####

####LOSS OVER  1  ITERATIONS:  0.8909040093421936  ##### ACC OVER  1  ITERATIONS: 0.7379719138145446  #####
####LOSS STANDARD DEVIATION OVER  1  ITERATIONS:  0.0  ACC STANDARD DEVIATION OVER  1  ITERATIONS: 0.0 #####
