2020-09-24 11:51:22.178709: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-09-24 11:51:22.178947: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-09-24 11:51:25.044317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f67813da70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-24 11:51:25.044563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-24 11:51:25.045621: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-09-24 11:51:25.045836: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-24 11:51:25.049900: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-OVHAIFS
2020-09-24 11:51:25.050173: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-OVHAIFS
WARNING:tensorflow:From C:/Users/mp95/PycharmProjects/Thesis/model/lstm_parselmouth2.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Using TensorFlow backend.
curdir: C:\Users\mp95\PycharmProjects\Thesis\model
started reading folder Sad
  0%|          | 0/84 [00:00<?, ?it/s] 27%|???       | 23/84 [00:00<00:00, 223.49it/s] 54%|??????    | 45/84 [00:00<00:00, 220.49it/s] 80%|????????  | 67/84 [00:00<00:00, 217.78it/s]100%|??????????| 84/84 [00:00<00:00, 213.38it/s]
ended reading folder Sad
started reading folder Happy
  0%|          | 0/84 [00:00<?, ?it/s] 26%|???       | 22/84 [00:00<00:00, 207.73it/s] 49%|?????     | 41/84 [00:00<00:00, 200.13it/s] 73%|????????  | 61/84 [00:00<00:00, 198.35it/s] 99%|??????????| 83/84 [00:00<00:00, 201.63it/s]100%|??????????| 84/84 [00:00<00:00, 199.63it/s]
ended reading folder Happy
started reading folder Angry
  0%|          | 0/84 [00:00<?, ?it/s] 24%|???       | 20/84 [00:00<00:00, 196.25it/s] 46%|?????     | 39/84 [00:00<00:00, 192.61it/s] 70%|???????   | 59/84 [00:00<00:00, 193.13it/s] 94%|??????????| 79/84 [00:00<00:00, 194.05it/s]100%|??????????| 84/84 [00:00<00:00, 193.71it/s]
ended reading folder Angry
started reading folder Neutral
  0%|          | 0/84 [00:00<?, ?it/s] 24%|???       | 20/84 [00:00<00:00, 196.25it/s] 49%|?????     | 41/84 [00:00<00:00, 199.66it/s] 74%|????????  | 62/84 [00:00<00:00, 202.12it/s]100%|??????????| 84/84 [00:00<00:00, 204.91it/s]100%|??????????| 84/84 [00:00<00:00, 206.06it/s]
ended reading folder Neutral

EXECUTION PARAMETERS: {NUMBER OF FOLDERS:  5 }-{NUMBER OF EPOCHS:  80 }-{NUMBER OF ROUTINE ITERATIONS:  1 }-{BATCH SIZE :  32 }-{SIGNAL MODE:  fp }-{AUGMENT: Sad }-{FEATURES:  mfcc }-{EMOTIONS: ('Sad', 'Happy', 'Angry', 'Neutral') }

####ITERATION NUMBER:  1

#####FOLDER NUMBER: 1
Starting LSTM
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 44, 13)            0         
_________________________________________________________________
lstm (LSTM)                  (None, 44, 128)           72704     
_________________________________________________________________
dropout (Dropout)            (None, 44, 128)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 64)                49408     
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense (Dense)                (None, 64)                4160      
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 260       
=================================================================
Total params: 126,532
Trainable params: 126,532
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/80
9/9 - 7s - loss: 1.4846 - accuracy: 0.2500 - val_loss: 1.2622 - val_accuracy: 0.3824
Epoch 2/80
9/9 - 1s - loss: 1.3183 - accuracy: 0.3209 - val_loss: 1.1131 - val_accuracy: 0.5735
Epoch 3/80
9/9 - 1s - loss: 1.1794 - accuracy: 0.4328 - val_loss: 1.0665 - val_accuracy: 0.4853
Epoch 4/80
9/9 - 1s - loss: 1.2284 - accuracy: 0.4590 - val_loss: 1.0703 - val_accuracy: 0.3676
Epoch 5/80
9/9 - 1s - loss: 1.0952 - accuracy: 0.4851 - val_loss: 1.0068 - val_accuracy: 0.5588
Epoch 6/80
9/9 - 1s - loss: 1.1414 - accuracy: 0.4963 - val_loss: 0.9881 - val_accuracy: 0.5147
Epoch 7/80
9/9 - 1s - loss: 1.0096 - accuracy: 0.5299 - val_loss: 0.9460 - val_accuracy: 0.5882
Epoch 8/80
9/9 - 1s - loss: 0.9900 - accuracy: 0.5410 - val_loss: 0.9342 - val_accuracy: 0.6324
Epoch 9/80
9/9 - 1s - loss: 0.9623 - accuracy: 0.5299 - val_loss: 0.9226 - val_accuracy: 0.5882
Epoch 10/80
9/9 - 1s - loss: 0.9181 - accuracy: 0.6231 - val_loss: 0.9192 - val_accuracy: 0.6176
Epoch 11/80
9/9 - 1s - loss: 0.8534 - accuracy: 0.6604 - val_loss: 0.8634 - val_accuracy: 0.6471
Epoch 12/80
9/9 - 1s - loss: 0.8771 - accuracy: 0.6455 - val_loss: 0.8319 - val_accuracy: 0.6324
Epoch 13/80
9/9 - 1s - loss: 0.7005 - accuracy: 0.7575 - val_loss: 0.8848 - val_accuracy: 0.5882
Epoch 14/80
9/9 - 1s - loss: 0.7555 - accuracy: 0.6567 - val_loss: 0.8592 - val_accuracy: 0.6324
Epoch 15/80
9/9 - 1s - loss: 0.6639 - accuracy: 0.7201 - val_loss: 0.8912 - val_accuracy: 0.6324
Epoch 16/80
9/9 - 1s - loss: 0.6668 - accuracy: 0.7463 - val_loss: 0.9711 - val_accuracy: 0.6176
Epoch 17/80
9/9 - 1s - loss: 0.6803 - accuracy: 0.7388 - val_loss: 0.7201 - val_accuracy: 0.6618
Epoch 18/80
9/9 - 1s - loss: 0.5361 - accuracy: 0.7873 - val_loss: 0.8032 - val_accuracy: 0.6912
Epoch 19/80
9/9 - 1s - loss: 0.6268 - accuracy: 0.7388 - val_loss: 0.9879 - val_accuracy: 0.6912
Epoch 20/80
9/9 - 1s - loss: 0.5324 - accuracy: 0.7612 - val_loss: 0.7841 - val_accuracy: 0.6471
Epoch 21/80
9/9 - 1s - loss: 0.4487 - accuracy: 0.8470 - val_loss: 0.7457 - val_accuracy: 0.7206
Epoch 22/80
9/9 - 1s - loss: 0.4217 - accuracy: 0.8172 - val_loss: 0.7371 - val_accuracy: 0.6765
Epoch 23/80
9/9 - 1s - loss: 0.3755 - accuracy: 0.8470 - val_loss: 0.8565 - val_accuracy: 0.6912
Epoch 24/80
9/9 - 1s - loss: 0.3277 - accuracy: 0.8881 - val_loss: 0.7272 - val_accuracy: 0.7647
Epoch 25/80
9/9 - 1s - loss: 0.3645 - accuracy: 0.8694 - val_loss: 0.7452 - val_accuracy: 0.7647
Epoch 26/80
9/9 - 1s - loss: 0.2561 - accuracy: 0.9179 - val_loss: 1.2110 - val_accuracy: 0.6176
Epoch 27/80
9/9 - 1s - loss: 0.2524 - accuracy: 0.9179 - val_loss: 0.6740 - val_accuracy: 0.7941
Epoch 28/80
9/9 - 1s - loss: 0.2630 - accuracy: 0.9254 - val_loss: 0.9678 - val_accuracy: 0.6912
Epoch 29/80
9/9 - 1s - loss: 0.3184 - accuracy: 0.8918 - val_loss: 1.2792 - val_accuracy: 0.6029
Epoch 30/80
9/9 - 1s - loss: 0.2438 - accuracy: 0.9142 - val_loss: 0.9736 - val_accuracy: 0.6912
Epoch 31/80
9/9 - 1s - loss: 0.1993 - accuracy: 0.9291 - val_loss: 1.0806 - val_accuracy: 0.6912
Epoch 32/80
9/9 - 1s - loss: 0.1848 - accuracy: 0.9403 - val_loss: 1.0338 - val_accuracy: 0.7353
Epoch 33/80
9/9 - 1s - loss: 0.1538 - accuracy: 0.9552 - val_loss: 1.0132 - val_accuracy: 0.7647
Epoch 34/80
9/9 - 1s - loss: 0.1432 - accuracy: 0.9515 - val_loss: 1.0433 - val_accuracy: 0.6765
Epoch 35/80
9/9 - 1s - loss: 0.0923 - accuracy: 0.9664 - val_loss: 1.0116 - val_accuracy: 0.7353
Epoch 36/80
9/9 - 1s - loss: 0.1900 - accuracy: 0.9440 - val_loss: 1.1398 - val_accuracy: 0.6618
Epoch 37/80
9/9 - 1s - loss: 0.0998 - accuracy: 0.9701 - val_loss: 1.0002 - val_accuracy: 0.7647
Epoch 38/80
9/9 - 1s - loss: 0.1078 - accuracy: 0.9739 - val_loss: 1.3276 - val_accuracy: 0.7059
Epoch 39/80
9/9 - 1s - loss: 0.0910 - accuracy: 0.9664 - val_loss: 1.1826 - val_accuracy: 0.7353
Epoch 40/80
9/9 - 1s - loss: 0.0804 - accuracy: 0.9776 - val_loss: 1.2762 - val_accuracy: 0.6912
Epoch 41/80
9/9 - 1s - loss: 0.0579 - accuracy: 0.9851 - val_loss: 1.3497 - val_accuracy: 0.6618
Epoch 42/80
9/9 - 1s - loss: 0.0704 - accuracy: 0.9776 - val_loss: 1.3032 - val_accuracy: 0.6912
Epoch 43/80
9/9 - 1s - loss: 0.1062 - accuracy: 0.9590 - val_loss: 1.0037 - val_accuracy: 0.7941
Epoch 44/80
9/9 - 1s - loss: 0.0687 - accuracy: 0.9888 - val_loss: 1.5002 - val_accuracy: 0.6471
Epoch 45/80
9/9 - 1s - loss: 0.0466 - accuracy: 0.9925 - val_loss: 1.3230 - val_accuracy: 0.6912
Epoch 46/80
9/9 - 1s - loss: 0.0467 - accuracy: 0.9888 - val_loss: 1.6799 - val_accuracy: 0.6912
Epoch 47/80
9/9 - 1s - loss: 0.0381 - accuracy: 0.9888 - val_loss: 1.5133 - val_accuracy: 0.7059
Epoch 00047: early stopping
best epoch: 27  loss: 0.6739572286605835  acc: 0.7941176295280457
[0.6739572286605835] [0.7941176295280457]
Accuracy:0.794

Confusion matrix:
 [[ 9  0  0  3]
 [ 0 21  1  2]
 [ 3  2 11  0]
 [ 1  2  0 13]]

#####FOLDER NUMBER: 2
Epoch 1/80
9/9 - 1s - loss: 1.4906 - accuracy: 0.2677 - val_loss: 1.3307 - val_accuracy: 0.3284
Epoch 2/80
9/9 - 1s - loss: 1.3835 - accuracy: 0.3383 - val_loss: 1.1764 - val_accuracy: 0.4627
Epoch 3/80
9/9 - 1s - loss: 1.2541 - accuracy: 0.4201 - val_loss: 1.0827 - val_accuracy: 0.4627
Epoch 4/80
9/9 - 1s - loss: 1.2322 - accuracy: 0.4201 - val_loss: 1.0449 - val_accuracy: 0.5224
Epoch 5/80
9/9 - 1s - loss: 1.1212 - accuracy: 0.5019 - val_loss: 0.9891 - val_accuracy: 0.4478
Epoch 6/80
9/9 - 1s - loss: 1.1146 - accuracy: 0.4721 - val_loss: 1.0262 - val_accuracy: 0.5373
Epoch 7/80
9/9 - 1s - loss: 1.1114 - accuracy: 0.5167 - val_loss: 0.9289 - val_accuracy: 0.5522
Epoch 8/80
9/9 - 1s - loss: 1.0398 - accuracy: 0.4944 - val_loss: 0.9902 - val_accuracy: 0.4179
Epoch 9/80
9/9 - 1s - loss: 1.0003 - accuracy: 0.5390 - val_loss: 0.9143 - val_accuracy: 0.5821
Epoch 10/80
9/9 - 1s - loss: 0.9601 - accuracy: 0.5762 - val_loss: 0.9820 - val_accuracy: 0.5970
Epoch 11/80
9/9 - 1s - loss: 0.9659 - accuracy: 0.5725 - val_loss: 0.9434 - val_accuracy: 0.5672
Epoch 12/80
9/9 - 1s - loss: 0.9619 - accuracy: 0.5688 - val_loss: 0.9671 - val_accuracy: 0.5970
Epoch 13/80
9/9 - 1s - loss: 0.8961 - accuracy: 0.5985 - val_loss: 0.9866 - val_accuracy: 0.5672
Epoch 14/80
9/9 - 1s - loss: 0.8938 - accuracy: 0.6283 - val_loss: 0.9208 - val_accuracy: 0.6269
Epoch 15/80
9/9 - 1s - loss: 0.8281 - accuracy: 0.6394 - val_loss: 0.9656 - val_accuracy: 0.5075
Epoch 16/80
9/9 - 1s - loss: 0.8222 - accuracy: 0.6617 - val_loss: 1.0013 - val_accuracy: 0.5522
Epoch 17/80
9/9 - 1s - loss: 0.7630 - accuracy: 0.6877 - val_loss: 1.0316 - val_accuracy: 0.5373
Epoch 18/80
9/9 - 1s - loss: 0.7853 - accuracy: 0.6914 - val_loss: 0.9439 - val_accuracy: 0.5672
Epoch 19/80
9/9 - 1s - loss: 0.7349 - accuracy: 0.6989 - val_loss: 0.9872 - val_accuracy: 0.5970
Epoch 20/80
9/9 - 1s - loss: 0.6424 - accuracy: 0.7546 - val_loss: 1.1448 - val_accuracy: 0.5224
Epoch 21/80
9/9 - 1s - loss: 0.7147 - accuracy: 0.7100 - val_loss: 1.3158 - val_accuracy: 0.5970
Epoch 22/80
9/9 - 1s - loss: 0.7695 - accuracy: 0.7212 - val_loss: 1.0321 - val_accuracy: 0.6269
Epoch 23/80
9/9 - 1s - loss: 0.6174 - accuracy: 0.8067 - val_loss: 1.1175 - val_accuracy: 0.5075
Epoch 24/80
9/9 - 1s - loss: 0.4972 - accuracy: 0.8513 - val_loss: 1.0429 - val_accuracy: 0.6119
Epoch 25/80
9/9 - 1s - loss: 0.5000 - accuracy: 0.8253 - val_loss: 1.1448 - val_accuracy: 0.5970
Epoch 26/80
9/9 - 1s - loss: 0.5319 - accuracy: 0.8253 - val_loss: 1.2353 - val_accuracy: 0.5821
Epoch 27/80
9/9 - 1s - loss: 0.4847 - accuracy: 0.8216 - val_loss: 1.1889 - val_accuracy: 0.5672
Epoch 28/80
9/9 - 1s - loss: 0.4829 - accuracy: 0.8364 - val_loss: 1.1870 - val_accuracy: 0.5522
Epoch 29/80
9/9 - 1s - loss: 0.4201 - accuracy: 0.8401 - val_loss: 1.1856 - val_accuracy: 0.5970
Epoch 30/80
9/9 - 1s - loss: 0.3916 - accuracy: 0.8625 - val_loss: 1.1555 - val_accuracy: 0.6119
Epoch 31/80
9/9 - 1s - loss: 0.4391 - accuracy: 0.8327 - val_loss: 1.2091 - val_accuracy: 0.6119
Epoch 32/80
9/9 - 1s - loss: 0.4019 - accuracy: 0.8662 - val_loss: 1.3677 - val_accuracy: 0.5672
Epoch 33/80
9/9 - 1s - loss: 0.2880 - accuracy: 0.8996 - val_loss: 1.2303 - val_accuracy: 0.6269
Epoch 34/80
9/9 - 1s - loss: 0.2805 - accuracy: 0.8996 - val_loss: 1.4929 - val_accuracy: 0.5522
Epoch 00034: early stopping
best epoch: 14  loss: 0.9207548499107361  acc: 0.6268656849861145
[0.6739572286605835, 0.9207548499107361] [0.7941176295280457, 0.6268656849861145]
Accuracy:0.627

Confusion matrix:
 [[12  0  0  5]
 [ 1  8  3  2]
 [ 0  3 15  2]
 [ 9  0  0  7]]

#####FOLDER NUMBER: 3
Epoch 1/80
9/9 - 1s - loss: 1.4961 - accuracy: 0.2714 - val_loss: 1.3263 - val_accuracy: 0.3582
Epoch 2/80
9/9 - 1s - loss: 1.3885 - accuracy: 0.3234 - val_loss: 1.2711 - val_accuracy: 0.4478
Epoch 3/80
9/9 - 1s - loss: 1.1755 - accuracy: 0.4424 - val_loss: 1.2069 - val_accuracy: 0.4627
Epoch 4/80
9/9 - 1s - loss: 1.1709 - accuracy: 0.4907 - val_loss: 1.2091 - val_accuracy: 0.4030
Epoch 5/80
9/9 - 1s - loss: 1.0823 - accuracy: 0.5056 - val_loss: 1.2625 - val_accuracy: 0.4179
Epoch 6/80
9/9 - 1s - loss: 1.1056 - accuracy: 0.4870 - val_loss: 1.1415 - val_accuracy: 0.4328
Epoch 7/80
9/9 - 1s - loss: 1.1075 - accuracy: 0.4796 - val_loss: 1.2277 - val_accuracy: 0.4478
Epoch 8/80
9/9 - 1s - loss: 1.0291 - accuracy: 0.5167 - val_loss: 1.0861 - val_accuracy: 0.4627
Epoch 9/80
9/9 - 1s - loss: 0.9787 - accuracy: 0.5353 - val_loss: 1.1804 - val_accuracy: 0.4030
Epoch 10/80
9/9 - 1s - loss: 1.0107 - accuracy: 0.5019 - val_loss: 1.1004 - val_accuracy: 0.4627
Epoch 11/80
9/9 - 1s - loss: 1.0024 - accuracy: 0.5465 - val_loss: 1.1942 - val_accuracy: 0.4478
Epoch 12/80
9/9 - 1s - loss: 0.9961 - accuracy: 0.5539 - val_loss: 1.0506 - val_accuracy: 0.4328
Epoch 13/80
9/9 - 1s - loss: 1.0077 - accuracy: 0.5242 - val_loss: 1.1311 - val_accuracy: 0.4776
Epoch 14/80
9/9 - 1s - loss: 0.9117 - accuracy: 0.5948 - val_loss: 1.0911 - val_accuracy: 0.4776
Epoch 15/80
9/9 - 1s - loss: 0.8558 - accuracy: 0.6803 - val_loss: 1.0856 - val_accuracy: 0.5075
Epoch 16/80
9/9 - 1s - loss: 0.8096 - accuracy: 0.6840 - val_loss: 1.0565 - val_accuracy: 0.5373
Epoch 17/80
9/9 - 1s - loss: 0.8153 - accuracy: 0.6729 - val_loss: 1.0770 - val_accuracy: 0.5075
Epoch 18/80
9/9 - 1s - loss: 0.8110 - accuracy: 0.6840 - val_loss: 1.0562 - val_accuracy: 0.5075
Epoch 19/80
9/9 - 1s - loss: 0.7638 - accuracy: 0.6803 - val_loss: 1.0192 - val_accuracy: 0.4925
Epoch 20/80
9/9 - 1s - loss: 0.7371 - accuracy: 0.7286 - val_loss: 0.9810 - val_accuracy: 0.5672
Epoch 21/80
9/9 - 1s - loss: 0.6901 - accuracy: 0.7249 - val_loss: 1.0291 - val_accuracy: 0.5970
Epoch 22/80
9/9 - 1s - loss: 0.6113 - accuracy: 0.7658 - val_loss: 0.9580 - val_accuracy: 0.6119
Epoch 23/80
9/9 - 1s - loss: 0.5938 - accuracy: 0.7695 - val_loss: 1.0760 - val_accuracy: 0.5821
Epoch 24/80
9/9 - 1s - loss: 0.5840 - accuracy: 0.7732 - val_loss: 1.0828 - val_accuracy: 0.6119
Epoch 25/80
9/9 - 1s - loss: 0.5692 - accuracy: 0.7807 - val_loss: 0.9912 - val_accuracy: 0.5821
Epoch 26/80
9/9 - 1s - loss: 0.4991 - accuracy: 0.8030 - val_loss: 0.9730 - val_accuracy: 0.6119
Epoch 27/80
9/9 - 1s - loss: 0.4942 - accuracy: 0.8067 - val_loss: 1.0002 - val_accuracy: 0.5970
Epoch 28/80
9/9 - 1s - loss: 0.4936 - accuracy: 0.8253 - val_loss: 1.0120 - val_accuracy: 0.6119
Epoch 29/80
9/9 - 1s - loss: 0.4328 - accuracy: 0.8587 - val_loss: 0.9791 - val_accuracy: 0.6716
Epoch 30/80
9/9 - 1s - loss: 0.4059 - accuracy: 0.8699 - val_loss: 1.3010 - val_accuracy: 0.5821
Epoch 31/80
9/9 - 1s - loss: 0.3890 - accuracy: 0.8662 - val_loss: 1.0316 - val_accuracy: 0.6418
Epoch 32/80
9/9 - 1s - loss: 0.4496 - accuracy: 0.8401 - val_loss: 1.0695 - val_accuracy: 0.6269
Epoch 33/80
9/9 - 1s - loss: 0.4300 - accuracy: 0.8439 - val_loss: 1.1657 - val_accuracy: 0.6269
Epoch 34/80
9/9 - 1s - loss: 0.3800 - accuracy: 0.8587 - val_loss: 0.9880 - val_accuracy: 0.6866
Epoch 35/80
9/9 - 1s - loss: 0.3150 - accuracy: 0.8773 - val_loss: 0.9287 - val_accuracy: 0.6866
Epoch 36/80
9/9 - 2s - loss: 0.2599 - accuracy: 0.9257 - val_loss: 1.0610 - val_accuracy: 0.7015
Epoch 37/80
9/9 - 1s - loss: 0.2178 - accuracy: 0.9405 - val_loss: 1.1663 - val_accuracy: 0.7015
Epoch 38/80
9/9 - 1s - loss: 0.1859 - accuracy: 0.9368 - val_loss: 1.2047 - val_accuracy: 0.6716
Epoch 39/80
9/9 - 1s - loss: 0.1450 - accuracy: 0.9554 - val_loss: 1.1904 - val_accuracy: 0.6716
Epoch 40/80
9/9 - 1s - loss: 0.1390 - accuracy: 0.9591 - val_loss: 1.2655 - val_accuracy: 0.6866
Epoch 41/80
9/9 - 1s - loss: 0.1265 - accuracy: 0.9554 - val_loss: 1.6426 - val_accuracy: 0.5821
Epoch 42/80
9/9 - 1s - loss: 0.2931 - accuracy: 0.8996 - val_loss: 1.2125 - val_accuracy: 0.6567
Epoch 43/80
9/9 - 1s - loss: 0.2692 - accuracy: 0.9071 - val_loss: 1.4298 - val_accuracy: 0.6418
Epoch 44/80
9/9 - 1s - loss: 0.2635 - accuracy: 0.9071 - val_loss: 1.0530 - val_accuracy: 0.6866
Epoch 45/80
9/9 - 1s - loss: 0.2708 - accuracy: 0.9071 - val_loss: 1.1162 - val_accuracy: 0.6716
Epoch 46/80
9/9 - 1s - loss: 0.2701 - accuracy: 0.9108 - val_loss: 1.4959 - val_accuracy: 0.6269
Epoch 47/80
9/9 - 1s - loss: 0.1662 - accuracy: 0.9405 - val_loss: 1.2943 - val_accuracy: 0.6418
Epoch 48/80
9/9 - 1s - loss: 0.1260 - accuracy: 0.9517 - val_loss: 1.2417 - val_accuracy: 0.6866
Epoch 49/80
9/9 - 1s - loss: 0.1049 - accuracy: 0.9703 - val_loss: 1.3235 - val_accuracy: 0.6567
Epoch 50/80
9/9 - 1s - loss: 0.0932 - accuracy: 0.9740 - val_loss: 1.2770 - val_accuracy: 0.6866
Epoch 51/80
9/9 - 1s - loss: 0.1759 - accuracy: 0.9591 - val_loss: 1.3193 - val_accuracy: 0.6866
Epoch 52/80
9/9 - 1s - loss: 0.1258 - accuracy: 0.9740 - val_loss: 1.4449 - val_accuracy: 0.6418
Epoch 53/80
9/9 - 1s - loss: 0.1321 - accuracy: 0.9591 - val_loss: 1.2740 - val_accuracy: 0.6866
Epoch 54/80
9/9 - 1s - loss: 0.0946 - accuracy: 0.9628 - val_loss: 1.2751 - val_accuracy: 0.7015
Epoch 55/80
9/9 - 1s - loss: 0.0485 - accuracy: 0.9851 - val_loss: 1.4162 - val_accuracy: 0.7015
Epoch 56/80
9/9 - 1s - loss: 0.0719 - accuracy: 0.9814 - val_loss: 1.4738 - val_accuracy: 0.6716
Epoch 00056: early stopping
best epoch: 36  loss: 1.060994267463684  acc: 0.7014925479888916
[0.6739572286605835, 0.9207548499107361, 1.060994267463684] [0.7941176295280457, 0.6268656849861145, 0.7014925479888916]
Accuracy:0.701

Confusion matrix:
 [[17  0  0  4]
 [ 1  7  4  0]
 [ 0  5 10  0]
 [ 1  3  2 13]]

#####FOLDER NUMBER: 4
Epoch 1/80
9/9 - 1s - loss: 1.4825 - accuracy: 0.2751 - val_loss: 1.3268 - val_accuracy: 0.3731
Epoch 2/80
9/9 - 1s - loss: 1.4016 - accuracy: 0.2825 - val_loss: 1.2351 - val_accuracy: 0.3881
Epoch 3/80
9/9 - 1s - loss: 1.2732 - accuracy: 0.3643 - val_loss: 1.1681 - val_accuracy: 0.4627
Epoch 4/80
9/9 - 1s - loss: 1.1924 - accuracy: 0.4164 - val_loss: 1.1458 - val_accuracy: 0.4179
Epoch 5/80
9/9 - 1s - loss: 1.1389 - accuracy: 0.4164 - val_loss: 1.1303 - val_accuracy: 0.4776
Epoch 6/80
9/9 - 1s - loss: 1.1033 - accuracy: 0.4610 - val_loss: 1.1560 - val_accuracy: 0.4925
Epoch 7/80
9/9 - 1s - loss: 1.0408 - accuracy: 0.5316 - val_loss: 1.1029 - val_accuracy: 0.4478
Epoch 8/80
9/9 - 1s - loss: 1.0892 - accuracy: 0.4907 - val_loss: 1.0965 - val_accuracy: 0.5373
Epoch 9/80
9/9 - 1s - loss: 0.9989 - accuracy: 0.5502 - val_loss: 1.1249 - val_accuracy: 0.4627
Epoch 10/80
9/9 - 1s - loss: 1.0185 - accuracy: 0.5465 - val_loss: 1.0959 - val_accuracy: 0.5075
Epoch 11/80
9/9 - 1s - loss: 1.0436 - accuracy: 0.5539 - val_loss: 1.0234 - val_accuracy: 0.5672
Epoch 12/80
9/9 - 1s - loss: 0.9621 - accuracy: 0.5762 - val_loss: 1.0838 - val_accuracy: 0.5672
Epoch 13/80
9/9 - 1s - loss: 0.9938 - accuracy: 0.5242 - val_loss: 1.0199 - val_accuracy: 0.5522
Epoch 14/80
9/9 - 1s - loss: 0.8995 - accuracy: 0.5465 - val_loss: 1.1017 - val_accuracy: 0.5075
Epoch 15/80
9/9 - 1s - loss: 0.9263 - accuracy: 0.5688 - val_loss: 1.0487 - val_accuracy: 0.5672
Epoch 16/80
9/9 - 1s - loss: 0.8846 - accuracy: 0.6022 - val_loss: 1.0705 - val_accuracy: 0.5224
Epoch 17/80
9/9 - 1s - loss: 0.8088 - accuracy: 0.6468 - val_loss: 1.0602 - val_accuracy: 0.6269
Epoch 18/80
9/9 - 1s - loss: 0.8088 - accuracy: 0.6654 - val_loss: 0.9996 - val_accuracy: 0.5970
Epoch 19/80
9/9 - 1s - loss: 0.7666 - accuracy: 0.6729 - val_loss: 1.0495 - val_accuracy: 0.6119
Epoch 20/80
9/9 - 1s - loss: 0.7467 - accuracy: 0.6691 - val_loss: 0.9799 - val_accuracy: 0.6567
Epoch 21/80
9/9 - 1s - loss: 0.7315 - accuracy: 0.7063 - val_loss: 0.9598 - val_accuracy: 0.6418
Epoch 22/80
9/9 - 1s - loss: 0.6409 - accuracy: 0.7509 - val_loss: 1.0455 - val_accuracy: 0.6418
Epoch 23/80
9/9 - 1s - loss: 0.7039 - accuracy: 0.7361 - val_loss: 0.9763 - val_accuracy: 0.6119
Epoch 24/80
9/9 - 1s - loss: 0.7004 - accuracy: 0.7063 - val_loss: 1.0401 - val_accuracy: 0.6269
Epoch 25/80
9/9 - 1s - loss: 0.6249 - accuracy: 0.7509 - val_loss: 1.0128 - val_accuracy: 0.6567
Epoch 26/80
9/9 - 1s - loss: 0.5809 - accuracy: 0.7732 - val_loss: 0.9823 - val_accuracy: 0.5821
Epoch 27/80
9/9 - 1s - loss: 0.5831 - accuracy: 0.7695 - val_loss: 1.0280 - val_accuracy: 0.6567
Epoch 28/80
9/9 - 1s - loss: 0.5055 - accuracy: 0.7993 - val_loss: 1.0827 - val_accuracy: 0.6269
Epoch 29/80
9/9 - 1s - loss: 0.4718 - accuracy: 0.8290 - val_loss: 1.0970 - val_accuracy: 0.5970
Epoch 30/80
9/9 - 1s - loss: 0.5049 - accuracy: 0.7844 - val_loss: 1.2553 - val_accuracy: 0.5522
Epoch 31/80
9/9 - 1s - loss: 0.5109 - accuracy: 0.8104 - val_loss: 1.1355 - val_accuracy: 0.6119
Epoch 32/80
9/9 - 1s - loss: 0.4901 - accuracy: 0.7918 - val_loss: 1.0924 - val_accuracy: 0.5821
Epoch 33/80
9/9 - 1s - loss: 0.4296 - accuracy: 0.8290 - val_loss: 1.1296 - val_accuracy: 0.5970
Epoch 34/80
9/9 - 1s - loss: 0.4406 - accuracy: 0.8364 - val_loss: 1.3280 - val_accuracy: 0.5970
Epoch 35/80
9/9 - 1s - loss: 0.5597 - accuracy: 0.7770 - val_loss: 1.0440 - val_accuracy: 0.7164
Epoch 36/80
9/9 - 1s - loss: 0.3663 - accuracy: 0.8810 - val_loss: 1.0935 - val_accuracy: 0.5821
Epoch 37/80
9/9 - 1s - loss: 0.3437 - accuracy: 0.8773 - val_loss: 1.0322 - val_accuracy: 0.6716
Epoch 38/80
9/9 - 1s - loss: 0.2790 - accuracy: 0.9071 - val_loss: 1.1792 - val_accuracy: 0.5821
Epoch 39/80
9/9 - 1s - loss: 0.2342 - accuracy: 0.9071 - val_loss: 1.0960 - val_accuracy: 0.6269
Epoch 40/80
9/9 - 1s - loss: 0.1840 - accuracy: 0.9294 - val_loss: 1.0393 - val_accuracy: 0.6418
Epoch 41/80
9/9 - 1s - loss: 0.1861 - accuracy: 0.9331 - val_loss: 1.4078 - val_accuracy: 0.5821
Epoch 42/80
9/9 - 1s - loss: 0.1756 - accuracy: 0.9368 - val_loss: 1.4107 - val_accuracy: 0.5672
Epoch 43/80
9/9 - 1s - loss: 0.1444 - accuracy: 0.9480 - val_loss: 1.4539 - val_accuracy: 0.5821
Epoch 44/80
9/9 - 1s - loss: 0.1689 - accuracy: 0.9480 - val_loss: 1.2898 - val_accuracy: 0.6716
Epoch 45/80
9/9 - 1s - loss: 0.3633 - accuracy: 0.8810 - val_loss: 1.7871 - val_accuracy: 0.6119
Epoch 46/80
9/9 - 1s - loss: 0.3547 - accuracy: 0.8773 - val_loss: 1.3615 - val_accuracy: 0.6269
Epoch 47/80
9/9 - 1s - loss: 0.3579 - accuracy: 0.8662 - val_loss: 1.0403 - val_accuracy: 0.6567
Epoch 48/80
9/9 - 1s - loss: 0.1830 - accuracy: 0.9294 - val_loss: 1.0915 - val_accuracy: 0.6567
Epoch 49/80
9/9 - 1s - loss: 0.1971 - accuracy: 0.9405 - val_loss: 1.0226 - val_accuracy: 0.6567
Epoch 50/80
9/9 - 1s - loss: 0.1430 - accuracy: 0.9628 - val_loss: 0.9785 - val_accuracy: 0.6567
Epoch 51/80
9/9 - 1s - loss: 0.1976 - accuracy: 0.9405 - val_loss: 1.2827 - val_accuracy: 0.6716
Epoch 52/80
9/9 - 1s - loss: 0.1248 - accuracy: 0.9517 - val_loss: 1.2815 - val_accuracy: 0.6716
Epoch 53/80
9/9 - 1s - loss: 0.1103 - accuracy: 0.9814 - val_loss: 1.2195 - val_accuracy: 0.7164
Epoch 54/80
9/9 - 1s - loss: 0.1053 - accuracy: 0.9777 - val_loss: 1.2988 - val_accuracy: 0.6716
Epoch 55/80
9/9 - 1s - loss: 0.0983 - accuracy: 0.9777 - val_loss: 1.4799 - val_accuracy: 0.6567
Epoch 00055: early stopping
best epoch: 35  loss: 1.0439807176589966  acc: 0.7164179086685181
[0.6739572286605835, 0.9207548499107361, 1.060994267463684, 1.0439807176589966] [0.7941176295280457, 0.6268656849861145, 0.7014925479888916, 0.7164179086685181]
Accuracy:0.716

Confusion matrix:
 [[13  1  0  1]
 [ 2 13  1  0]
 [ 0  5 12  1]
 [ 3  4  1 10]]

#####FOLDER NUMBER: 5
Epoch 1/80
9/9 - 1s - loss: 1.5442 - accuracy: 0.2379 - val_loss: 1.3431 - val_accuracy: 0.3284
Epoch 2/80
9/9 - 1s - loss: 1.3974 - accuracy: 0.3086 - val_loss: 1.2707 - val_accuracy: 0.3582
Epoch 3/80
9/9 - 1s - loss: 1.2839 - accuracy: 0.3755 - val_loss: 1.2148 - val_accuracy: 0.4179
Epoch 4/80
9/9 - 1s - loss: 1.2187 - accuracy: 0.4089 - val_loss: 1.1804 - val_accuracy: 0.4328
Epoch 5/80
9/9 - 1s - loss: 1.1610 - accuracy: 0.4312 - val_loss: 1.1642 - val_accuracy: 0.4328
Epoch 6/80
9/9 - 1s - loss: 1.1067 - accuracy: 0.4535 - val_loss: 1.1248 - val_accuracy: 0.5224
Epoch 7/80
9/9 - 1s - loss: 1.0953 - accuracy: 0.4684 - val_loss: 1.1126 - val_accuracy: 0.5373
Epoch 8/80
9/9 - 1s - loss: 1.1016 - accuracy: 0.4610 - val_loss: 1.1117 - val_accuracy: 0.4925
Epoch 9/80
9/9 - 1s - loss: 1.0189 - accuracy: 0.4981 - val_loss: 1.0852 - val_accuracy: 0.5373
Epoch 10/80
9/9 - 1s - loss: 1.0052 - accuracy: 0.5353 - val_loss: 1.0945 - val_accuracy: 0.5075
Epoch 11/80
9/9 - 1s - loss: 1.0282 - accuracy: 0.5353 - val_loss: 1.0834 - val_accuracy: 0.5224
Epoch 12/80
9/9 - 1s - loss: 0.9828 - accuracy: 0.5167 - val_loss: 1.0641 - val_accuracy: 0.5970
Epoch 13/80
9/9 - 1s - loss: 0.9910 - accuracy: 0.5242 - val_loss: 1.0549 - val_accuracy: 0.5224
Epoch 14/80
9/9 - 1s - loss: 0.9503 - accuracy: 0.5688 - val_loss: 1.0136 - val_accuracy: 0.5522
Epoch 15/80
9/9 - 1s - loss: 0.9020 - accuracy: 0.6059 - val_loss: 1.0216 - val_accuracy: 0.6269
Epoch 16/80
9/9 - 1s - loss: 0.9114 - accuracy: 0.5836 - val_loss: 1.0011 - val_accuracy: 0.5373
Epoch 17/80
9/9 - 1s - loss: 0.9121 - accuracy: 0.5576 - val_loss: 1.0360 - val_accuracy: 0.5224
Epoch 18/80
9/9 - 1s - loss: 0.8449 - accuracy: 0.6097 - val_loss: 0.9870 - val_accuracy: 0.5672
Epoch 19/80
9/9 - 1s - loss: 0.7909 - accuracy: 0.6357 - val_loss: 1.0953 - val_accuracy: 0.5821
Epoch 20/80
9/9 - 1s - loss: 0.8070 - accuracy: 0.6543 - val_loss: 0.9325 - val_accuracy: 0.5821
Epoch 21/80
9/9 - 1s - loss: 0.7798 - accuracy: 0.6506 - val_loss: 0.9626 - val_accuracy: 0.6119
Epoch 22/80
9/9 - 1s - loss: 0.7175 - accuracy: 0.7175 - val_loss: 0.9336 - val_accuracy: 0.6716
Epoch 23/80
9/9 - 1s - loss: 0.6812 - accuracy: 0.7509 - val_loss: 0.9907 - val_accuracy: 0.6418
Epoch 24/80
9/9 - 1s - loss: 0.6969 - accuracy: 0.6952 - val_loss: 0.8864 - val_accuracy: 0.6866
Epoch 25/80
9/9 - 1s - loss: 0.7000 - accuracy: 0.7100 - val_loss: 0.9689 - val_accuracy: 0.6119
Epoch 26/80
9/9 - 1s - loss: 0.6814 - accuracy: 0.7063 - val_loss: 0.9721 - val_accuracy: 0.6269
Epoch 27/80
9/9 - 1s - loss: 0.6192 - accuracy: 0.7621 - val_loss: 0.8760 - val_accuracy: 0.6567
Epoch 28/80
9/9 - 1s - loss: 0.6692 - accuracy: 0.7323 - val_loss: 0.9643 - val_accuracy: 0.6418
Epoch 29/80
9/9 - 1s - loss: 0.5850 - accuracy: 0.7472 - val_loss: 0.9178 - val_accuracy: 0.6716
Epoch 30/80
9/9 - 2s - loss: 0.5631 - accuracy: 0.7584 - val_loss: 0.9825 - val_accuracy: 0.5821
Epoch 31/80
9/9 - 1s - loss: 0.4817 - accuracy: 0.8253 - val_loss: 0.9768 - val_accuracy: 0.6418
Epoch 32/80
9/9 - 1s - loss: 0.4567 - accuracy: 0.8253 - val_loss: 0.9810 - val_accuracy: 0.6567
Epoch 33/80
9/9 - 1s - loss: 0.4748 - accuracy: 0.8030 - val_loss: 1.0423 - val_accuracy: 0.6567
Epoch 34/80
9/9 - 1s - loss: 0.4154 - accuracy: 0.8327 - val_loss: 0.9901 - val_accuracy: 0.6716
Epoch 35/80
9/9 - 1s - loss: 0.4512 - accuracy: 0.8141 - val_loss: 1.0647 - val_accuracy: 0.7164
Epoch 36/80
9/9 - 1s - loss: 0.3934 - accuracy: 0.8513 - val_loss: 0.9999 - val_accuracy: 0.6716
Epoch 37/80
9/9 - 1s - loss: 0.3433 - accuracy: 0.8662 - val_loss: 0.9667 - val_accuracy: 0.6866
Epoch 38/80
9/9 - 1s - loss: 0.3116 - accuracy: 0.8773 - val_loss: 1.0314 - val_accuracy: 0.6716
Epoch 39/80
9/9 - 1s - loss: 0.3324 - accuracy: 0.8662 - val_loss: 1.1154 - val_accuracy: 0.7313
Epoch 40/80
9/9 - 1s - loss: 0.3328 - accuracy: 0.8810 - val_loss: 1.1926 - val_accuracy: 0.6716
Epoch 41/80
9/9 - 1s - loss: 0.2583 - accuracy: 0.9219 - val_loss: 0.9742 - val_accuracy: 0.7164
Epoch 42/80
9/9 - 1s - loss: 0.3074 - accuracy: 0.8662 - val_loss: 1.0191 - val_accuracy: 0.6866
Epoch 43/80
9/9 - 1s - loss: 0.2309 - accuracy: 0.9182 - val_loss: 1.1942 - val_accuracy: 0.7164
Epoch 44/80
9/9 - 1s - loss: 0.2572 - accuracy: 0.8996 - val_loss: 0.8927 - val_accuracy: 0.7164
Epoch 45/80
9/9 - 1s - loss: 0.2274 - accuracy: 0.9182 - val_loss: 1.0369 - val_accuracy: 0.7164
Epoch 46/80
9/9 - 1s - loss: 0.2317 - accuracy: 0.9145 - val_loss: 1.2355 - val_accuracy: 0.7164
Epoch 47/80
9/9 - 1s - loss: 0.2273 - accuracy: 0.9108 - val_loss: 1.0755 - val_accuracy: 0.7015
Epoch 48/80
9/9 - 1s - loss: 0.1753 - accuracy: 0.9442 - val_loss: 1.0548 - val_accuracy: 0.7313
Epoch 49/80
9/9 - 1s - loss: 0.1402 - accuracy: 0.9554 - val_loss: 1.1232 - val_accuracy: 0.7015
Epoch 50/80
9/9 - 1s - loss: 0.1712 - accuracy: 0.9442 - val_loss: 1.1368 - val_accuracy: 0.7164
Epoch 51/80
9/9 - 1s - loss: 0.1433 - accuracy: 0.9554 - val_loss: 1.3225 - val_accuracy: 0.7015
Epoch 52/80
9/9 - 1s - loss: 0.1069 - accuracy: 0.9591 - val_loss: 1.2847 - val_accuracy: 0.6866
Epoch 53/80
9/9 - 1s - loss: 0.0702 - accuracy: 0.9888 - val_loss: 1.1644 - val_accuracy: 0.7164
Epoch 54/80
9/9 - 1s - loss: 0.0712 - accuracy: 0.9814 - val_loss: 1.2788 - val_accuracy: 0.7313
Epoch 55/80
9/9 - 1s - loss: 0.0905 - accuracy: 0.9777 - val_loss: 1.1814 - val_accuracy: 0.7015
Epoch 56/80
9/9 - 1s - loss: 0.0798 - accuracy: 0.9740 - val_loss: 1.5170 - val_accuracy: 0.7015
Epoch 57/80
9/9 - 1s - loss: 0.2561 - accuracy: 0.9071 - val_loss: 1.4766 - val_accuracy: 0.6866
Epoch 58/80
9/9 - 1s - loss: 0.1922 - accuracy: 0.9405 - val_loss: 1.5255 - val_accuracy: 0.6866
Epoch 59/80
9/9 - 1s - loss: 0.1962 - accuracy: 0.9294 - val_loss: 1.2106 - val_accuracy: 0.7015
Epoch 00059: early stopping
best epoch: 39  loss: 1.1153500080108643  acc: 0.7313432693481445
[0.6739572286605835, 0.9207548499107361, 1.060994267463684, 1.0439807176589966, 1.1153500080108643] [0.7941176295280457, 0.6268656849861145, 0.7014925479888916, 0.7164179086685181, 0.7313432693481445]
Accuracy:0.731

Confusion matrix:
 [[14  2  0  3]
 [ 0 16  0  2]
 [ 1  3  9  2]
 [ 1  4  0 10]]


 ############# AVERAGE EVALUATIONS ############

######### MEAN LOSS OVER THE 5 FOLDERS: 0.9630074143409729  ###########
######### MEAN ACCURACY OVER THE 5 FOLDERS: 0.7140474081039428  ###########
######### LOSS STANDARD DEVIATION OVER THE 5 FOLDERS: 0.1579250797840501  ###########
######### ACC STANDARD DEVIATION OVER THE 5 FOLDERS: 0.053803873106519705  ###########

####MEAN LOSSES OF THE FIRST  1  ITERATIONS:  [0.9630074143409729]  MEAN ACC OF THE FIRST  1  ITERATIONS:  [0.7140474081039428]  #####
####LOSSES STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  ACC STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  #####

####LOSS OVER  1  ITERATIONS:  0.9630074143409729  ##### ACC OVER  1  ITERATIONS: 0.7140474081039428  #####
####LOSS STANDARD DEVIATION OVER  1  ITERATIONS:  0.0  ACC STANDARD DEVIATION OVER  1  ITERATIONS: 0.0 #####
