2020-09-24 11:19:07.314087: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-09-24 11:19:07.314337: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-09-24 11:19:10.251129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2cdbea899a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-24 11:19:10.251375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-24 11:19:10.252457: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-09-24 11:19:10.252679: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-24 11:19:10.256581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-OVHAIFS
2020-09-24 11:19:10.256867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-OVHAIFS
WARNING:tensorflow:From C:/Users/mp95/PycharmProjects/Thesis/model/lstm_parselmouth2.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Using TensorFlow backend.
curdir: C:\Users\mp95\PycharmProjects\Thesis\model
started reading folder Sad
  0%|          | 0/84 [00:00<?, ?it/s] 27%|???       | 23/84 [00:00<00:00, 219.24it/s] 52%|??????    | 44/84 [00:00<00:00, 213.15it/s] 74%|????????  | 62/84 [00:00<00:00, 201.37it/s]100%|??????????| 84/84 [00:00<00:00, 204.86it/s]100%|??????????| 84/84 [00:00<00:00, 202.52it/s]
ended reading folder Sad
started reading folder Happy
  0%|          | 0/84 [00:00<?, ?it/s] 26%|???       | 22/84 [00:00<00:00, 215.87it/s] 40%|????      | 34/84 [00:00<00:00, 169.05it/s] 62%|???????   | 52/84 [00:00<00:00, 171.25it/s] 87%|????????? | 73/84 [00:00<00:00, 179.01it/s]100%|??????????| 84/84 [00:00<00:00, 177.74it/s]
ended reading folder Happy
started reading folder Angry
  0%|          | 0/84 [00:00<?, ?it/s] 25%|???       | 21/84 [00:00<00:00, 208.10it/s] 49%|?????     | 41/84 [00:00<00:00, 205.02it/s] 74%|????????  | 62/84 [00:00<00:00, 203.54it/s] 98%|??????????| 82/84 [00:00<00:00, 201.30it/s]100%|??????????| 84/84 [00:00<00:00, 200.17it/s]
ended reading folder Angry
started reading folder Neutral
  0%|          | 0/84 [00:00<?, ?it/s] 26%|???       | 22/84 [00:00<00:00, 217.76it/s] 52%|??????    | 44/84 [00:00<00:00, 217.19it/s] 76%|????????  | 64/84 [00:00<00:00, 210.45it/s]100%|??????????| 84/84 [00:00<00:00, 206.62it/s]100%|??????????| 84/84 [00:00<00:00, 207.01it/s]
ended reading folder Neutral

EXECUTION PARAMETERS: {NUMBER OF FOLDERS:  5 }-{NUMBER OF EPOCHS:  80 }-{NUMBER OF ROUTINE ITERATIONS:  1 }-{BATCH SIZE :  32 }-{SIGNAL MODE:  fp }-{AUGMENT: Sad }-{FEATURES:  mfcc }-{EMOTIONS: ('Sad', 'Happy', 'Angry', 'Neutral') }

####ITERATION NUMBER:  1

#####FOLDER NUMBER: 1
Starting LSTM
None
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 44, 13)            0         
_________________________________________________________________
lstm (LSTM)                  (None, 128)               72704     
_________________________________________________________________
dense (Dense)                (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 260       
=================================================================
Total params: 81,220
Trainable params: 81,220
Non-trainable params: 0
_________________________________________________________________
Epoch 1/80
9/9 - 3s - loss: 1.3096 - accuracy: 0.3918 - val_loss: 1.1549 - val_accuracy: 0.5000
Epoch 2/80
9/9 - 0s - loss: 1.0726 - accuracy: 0.5261 - val_loss: 1.0518 - val_accuracy: 0.5000
Epoch 3/80
9/9 - 0s - loss: 0.9517 - accuracy: 0.6082 - val_loss: 0.9748 - val_accuracy: 0.4853
Epoch 4/80
9/9 - 1s - loss: 0.8935 - accuracy: 0.5784 - val_loss: 0.9993 - val_accuracy: 0.5294
Epoch 5/80
9/9 - 0s - loss: 0.7785 - accuracy: 0.6791 - val_loss: 0.9375 - val_accuracy: 0.5294
Epoch 6/80
9/9 - 0s - loss: 0.7151 - accuracy: 0.7164 - val_loss: 0.9129 - val_accuracy: 0.5441
Epoch 7/80
9/9 - 0s - loss: 0.6504 - accuracy: 0.7313 - val_loss: 0.8284 - val_accuracy: 0.6029
Epoch 8/80
9/9 - 0s - loss: 0.5877 - accuracy: 0.7799 - val_loss: 0.8217 - val_accuracy: 0.6324
Epoch 9/80
9/9 - 0s - loss: 0.5030 - accuracy: 0.8433 - val_loss: 0.8088 - val_accuracy: 0.5882
Epoch 10/80
9/9 - 0s - loss: 0.4487 - accuracy: 0.8396 - val_loss: 0.7650 - val_accuracy: 0.6765
Epoch 11/80
9/9 - 0s - loss: 0.3879 - accuracy: 0.8657 - val_loss: 0.9619 - val_accuracy: 0.6324
Epoch 12/80
9/9 - 0s - loss: 0.3587 - accuracy: 0.8694 - val_loss: 0.9438 - val_accuracy: 0.5294
Epoch 13/80
9/9 - 0s - loss: 0.3220 - accuracy: 0.8731 - val_loss: 1.0123 - val_accuracy: 0.5147
Epoch 14/80
9/9 - 0s - loss: 0.2361 - accuracy: 0.9403 - val_loss: 0.8423 - val_accuracy: 0.6618
Epoch 15/80
9/9 - 0s - loss: 0.1882 - accuracy: 0.9664 - val_loss: 0.8548 - val_accuracy: 0.6471
Epoch 16/80
9/9 - 0s - loss: 0.1532 - accuracy: 0.9627 - val_loss: 0.9204 - val_accuracy: 0.6029
Epoch 17/80
9/9 - 0s - loss: 0.1218 - accuracy: 0.9813 - val_loss: 0.7701 - val_accuracy: 0.6324
Epoch 18/80
9/9 - 0s - loss: 0.0935 - accuracy: 0.9888 - val_loss: 0.8845 - val_accuracy: 0.6471
Epoch 19/80
9/9 - 1s - loss: 0.0720 - accuracy: 0.9925 - val_loss: 0.8908 - val_accuracy: 0.6324
Epoch 20/80
9/9 - 0s - loss: 0.0507 - accuracy: 0.9963 - val_loss: 0.8671 - val_accuracy: 0.6765
Epoch 21/80
9/9 - 0s - loss: 0.0390 - accuracy: 0.9963 - val_loss: 0.9935 - val_accuracy: 0.6029
Epoch 22/80
9/9 - 0s - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.6765
Epoch 23/80
9/9 - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.6029
Epoch 24/80
9/9 - 0s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.6324
Epoch 25/80
9/9 - 0s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.6471
Epoch 26/80
9/9 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.6471
Epoch 27/80
9/9 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0274 - val_accuracy: 0.6176
Epoch 28/80
9/9 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.6324
Epoch 29/80
9/9 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.6324
Epoch 30/80
9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0889 - val_accuracy: 0.6618
Epoch 00030: early stopping
best epoch: 10  loss: 0.7649983167648315  acc: 0.6764705777168274
[0.7649983167648315] [0.6764705777168274]
Accuracy:0.676

Confusion matrix:
 [[ 7  0  0  5]
 [ 0 21  1  2]
 [ 1  5  9  1]
 [ 2  5  0  9]]

#####FOLDER NUMBER: 2
Epoch 1/80
9/9 - 1s - loss: 1.3502 - accuracy: 0.2825 - val_loss: 1.2739 - val_accuracy: 0.3433
Epoch 2/80
9/9 - 1s - loss: 1.1567 - accuracy: 0.4981 - val_loss: 1.1057 - val_accuracy: 0.4328
Epoch 3/80
9/9 - 1s - loss: 1.0175 - accuracy: 0.5725 - val_loss: 1.0844 - val_accuracy: 0.4328
Epoch 4/80
9/9 - 1s - loss: 0.8953 - accuracy: 0.6208 - val_loss: 1.0365 - val_accuracy: 0.5224
Epoch 5/80
9/9 - 0s - loss: 0.7949 - accuracy: 0.6691 - val_loss: 1.0304 - val_accuracy: 0.5224
Epoch 6/80
9/9 - 1s - loss: 0.7139 - accuracy: 0.7100 - val_loss: 1.0003 - val_accuracy: 0.5373
Epoch 7/80
9/9 - 0s - loss: 0.6443 - accuracy: 0.7584 - val_loss: 1.0491 - val_accuracy: 0.4925
Epoch 8/80
9/9 - 1s - loss: 0.5695 - accuracy: 0.8067 - val_loss: 0.9908 - val_accuracy: 0.5224
Epoch 9/80
9/9 - 0s - loss: 0.5255 - accuracy: 0.7881 - val_loss: 0.9938 - val_accuracy: 0.5373
Epoch 10/80
9/9 - 0s - loss: 0.4337 - accuracy: 0.8662 - val_loss: 1.0662 - val_accuracy: 0.5672
Epoch 11/80
9/9 - 1s - loss: 0.4185 - accuracy: 0.8587 - val_loss: 1.1366 - val_accuracy: 0.5075
Epoch 12/80
9/9 - 0s - loss: 0.4631 - accuracy: 0.8253 - val_loss: 1.1703 - val_accuracy: 0.5224
Epoch 13/80
9/9 - 1s - loss: 0.3957 - accuracy: 0.8513 - val_loss: 0.9463 - val_accuracy: 0.5970
Epoch 14/80
9/9 - 1s - loss: 0.3482 - accuracy: 0.8773 - val_loss: 0.9731 - val_accuracy: 0.5522
Epoch 15/80
9/9 - 1s - loss: 0.3031 - accuracy: 0.9071 - val_loss: 1.0830 - val_accuracy: 0.5075
Epoch 16/80
9/9 - 0s - loss: 0.2164 - accuracy: 0.9591 - val_loss: 1.0221 - val_accuracy: 0.5672
Epoch 17/80
9/9 - 1s - loss: 0.1776 - accuracy: 0.9740 - val_loss: 1.0433 - val_accuracy: 0.5224
Epoch 18/80
9/9 - 1s - loss: 0.1411 - accuracy: 0.9740 - val_loss: 1.0480 - val_accuracy: 0.5970
Epoch 19/80
9/9 - 0s - loss: 0.1284 - accuracy: 0.9740 - val_loss: 1.0583 - val_accuracy: 0.5821
Epoch 20/80
9/9 - 0s - loss: 0.1029 - accuracy: 0.9814 - val_loss: 1.0804 - val_accuracy: 0.5970
Epoch 21/80
9/9 - 0s - loss: 0.0851 - accuracy: 0.9851 - val_loss: 1.1803 - val_accuracy: 0.5821
Epoch 22/80
9/9 - 0s - loss: 0.0651 - accuracy: 0.9963 - val_loss: 1.1401 - val_accuracy: 0.5821
Epoch 23/80
9/9 - 0s - loss: 0.0572 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.5821
Epoch 24/80
9/9 - 0s - loss: 0.0448 - accuracy: 0.9963 - val_loss: 1.1688 - val_accuracy: 0.6418
Epoch 25/80
9/9 - 0s - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.6119
Epoch 26/80
9/9 - 0s - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.2673 - val_accuracy: 0.6269
Epoch 27/80
9/9 - 0s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.6418
Epoch 28/80
9/9 - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.6418
Epoch 29/80
9/9 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3442 - val_accuracy: 0.6269
Epoch 30/80
9/9 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.6418
Epoch 31/80
9/9 - 1s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.6418
Epoch 32/80
9/9 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.6418
Epoch 33/80
9/9 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.4534 - val_accuracy: 0.6119
Epoch 34/80
9/9 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4276 - val_accuracy: 0.6269
Epoch 35/80
9/9 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.4695 - val_accuracy: 0.6119
Epoch 36/80
9/9 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.6269
Epoch 37/80
9/9 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4804 - val_accuracy: 0.6418
Epoch 38/80
9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.5022 - val_accuracy: 0.6119
Epoch 39/80
9/9 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.5345 - val_accuracy: 0.6269
Epoch 40/80
9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.6269
Epoch 41/80
9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5343 - val_accuracy: 0.6269
Epoch 42/80
9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.6119
Epoch 43/80
9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5819 - val_accuracy: 0.6418
Epoch 44/80
9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5863 - val_accuracy: 0.6418
Epoch 00044: early stopping
best epoch: 24  loss: 1.1687507629394531  acc: 0.641791045665741
[0.7649983167648315, 1.1687507629394531] [0.6764705777168274, 0.641791045665741]
Accuracy:0.642

Confusion matrix:
 [[12  1  1  3]
 [ 2 10  2  0]
 [ 0  4 12  4]
 [ 6  0  1  9]]

#####FOLDER NUMBER: 3
Epoch 1/80
9/9 - 1s - loss: 1.3387 - accuracy: 0.3234 - val_loss: 1.2326 - val_accuracy: 0.3582
Epoch 2/80
9/9 - 1s - loss: 1.1401 - accuracy: 0.4944 - val_loss: 1.1648 - val_accuracy: 0.4627
Epoch 3/80
9/9 - 1s - loss: 1.0071 - accuracy: 0.5762 - val_loss: 1.0768 - val_accuracy: 0.4776
Epoch 4/80
9/9 - 0s - loss: 0.8982 - accuracy: 0.6320 - val_loss: 1.0560 - val_accuracy: 0.4627
Epoch 5/80
9/9 - 1s - loss: 0.8313 - accuracy: 0.6468 - val_loss: 1.1289 - val_accuracy: 0.4776
Epoch 6/80
9/9 - 1s - loss: 0.7752 - accuracy: 0.6952 - val_loss: 0.9797 - val_accuracy: 0.5373
Epoch 7/80
9/9 - 1s - loss: 0.6753 - accuracy: 0.7398 - val_loss: 1.0562 - val_accuracy: 0.5373
Epoch 8/80
9/9 - 1s - loss: 0.6259 - accuracy: 0.7546 - val_loss: 1.0258 - val_accuracy: 0.5224
Epoch 9/80
9/9 - 1s - loss: 0.5826 - accuracy: 0.7435 - val_loss: 1.0239 - val_accuracy: 0.4925
Epoch 10/80
9/9 - 1s - loss: 0.4793 - accuracy: 0.8067 - val_loss: 0.9035 - val_accuracy: 0.5672
Epoch 11/80
9/9 - 1s - loss: 0.4406 - accuracy: 0.8662 - val_loss: 1.0874 - val_accuracy: 0.5224
Epoch 12/80
9/9 - 1s - loss: 0.3487 - accuracy: 0.8810 - val_loss: 0.9796 - val_accuracy: 0.6269
Epoch 13/80
9/9 - 1s - loss: 0.2950 - accuracy: 0.9108 - val_loss: 0.9991 - val_accuracy: 0.5672
Epoch 14/80
9/9 - 1s - loss: 0.2264 - accuracy: 0.9480 - val_loss: 1.0061 - val_accuracy: 0.6119
Epoch 15/80
9/9 - 1s - loss: 0.1762 - accuracy: 0.9665 - val_loss: 0.9913 - val_accuracy: 0.6418
Epoch 16/80
9/9 - 1s - loss: 0.1515 - accuracy: 0.9740 - val_loss: 1.1297 - val_accuracy: 0.5373
Epoch 17/80
9/9 - 1s - loss: 0.1149 - accuracy: 0.9888 - val_loss: 1.0449 - val_accuracy: 0.6716
Epoch 18/80
9/9 - 1s - loss: 0.0966 - accuracy: 0.9777 - val_loss: 1.0168 - val_accuracy: 0.5821
Epoch 19/80
9/9 - 0s - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.6418
Epoch 20/80
9/9 - 0s - loss: 0.0543 - accuracy: 0.9963 - val_loss: 1.2008 - val_accuracy: 0.5672
Epoch 21/80
9/9 - 0s - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.6269
Epoch 22/80
9/9 - 0s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.6119
Epoch 23/80
9/9 - 0s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.0709 - val_accuracy: 0.6269
Epoch 24/80
9/9 - 0s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.6119
Epoch 25/80
9/9 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.1509 - val_accuracy: 0.6269
Epoch 26/80
9/9 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.6567
Epoch 27/80
9/9 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1999 - val_accuracy: 0.6418
Epoch 28/80
9/9 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.6567
Epoch 29/80
9/9 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.6567
Epoch 30/80
9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.6567
Epoch 31/80
9/9 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.6567
Epoch 32/80
9/9 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.6567
Epoch 33/80
9/9 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2168 - val_accuracy: 0.6567
Epoch 34/80
9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2114 - val_accuracy: 0.6418
Epoch 35/80
9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 0.6567
Epoch 36/80
9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.6567
Epoch 37/80
9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.6418
Epoch 00037: early stopping
best epoch: 17  loss: 1.0449234247207642  acc: 0.6716417670249939
[0.7649983167648315, 1.1687507629394531, 1.0449234247207642] [0.6764705777168274, 0.641791045665741, 0.6716417670249939]
Accuracy:0.672

Confusion matrix:
 [[18  0  0  3]
 [ 0  8  2  2]
 [ 0  7  5  3]
 [ 3  2  0 14]]

#####FOLDER NUMBER: 4
Epoch 1/80
9/9 - 1s - loss: 1.3352 - accuracy: 0.3346 - val_loss: 1.2526 - val_accuracy: 0.3582
Epoch 2/80
9/9 - 0s - loss: 1.1349 - accuracy: 0.4870 - val_loss: 1.1283 - val_accuracy: 0.5224
Epoch 3/80
9/9 - 0s - loss: 0.9948 - accuracy: 0.5502 - val_loss: 1.0787 - val_accuracy: 0.5224
Epoch 4/80
9/9 - 1s - loss: 0.8895 - accuracy: 0.5948 - val_loss: 1.0306 - val_accuracy: 0.5672
Epoch 5/80
9/9 - 1s - loss: 0.8107 - accuracy: 0.6320 - val_loss: 1.0285 - val_accuracy: 0.5821
Epoch 6/80
9/9 - 1s - loss: 0.7248 - accuracy: 0.6803 - val_loss: 1.0045 - val_accuracy: 0.5522
Epoch 7/80
9/9 - 1s - loss: 0.6527 - accuracy: 0.7323 - val_loss: 0.9939 - val_accuracy: 0.5672
Epoch 8/80
9/9 - 1s - loss: 0.6055 - accuracy: 0.7546 - val_loss: 1.1216 - val_accuracy: 0.5373
Epoch 9/80
9/9 - 1s - loss: 0.6196 - accuracy: 0.7249 - val_loss: 0.9682 - val_accuracy: 0.6269
Epoch 10/80
9/9 - 0s - loss: 0.4889 - accuracy: 0.8030 - val_loss: 0.9862 - val_accuracy: 0.6119
Epoch 11/80
9/9 - 1s - loss: 0.4271 - accuracy: 0.8550 - val_loss: 0.9941 - val_accuracy: 0.5970
Epoch 12/80
9/9 - 1s - loss: 0.3847 - accuracy: 0.8513 - val_loss: 0.9497 - val_accuracy: 0.6269
Epoch 13/80
9/9 - 0s - loss: 0.3162 - accuracy: 0.8736 - val_loss: 1.0102 - val_accuracy: 0.6269
Epoch 14/80
9/9 - 0s - loss: 0.2419 - accuracy: 0.9219 - val_loss: 1.1147 - val_accuracy: 0.6119
Epoch 15/80
9/9 - 0s - loss: 0.2310 - accuracy: 0.9405 - val_loss: 1.0676 - val_accuracy: 0.6269
Epoch 16/80
9/9 - 1s - loss: 0.2475 - accuracy: 0.9182 - val_loss: 1.0414 - val_accuracy: 0.6567
Epoch 17/80
9/9 - 0s - loss: 0.1920 - accuracy: 0.9591 - val_loss: 1.1133 - val_accuracy: 0.6418
Epoch 18/80
9/9 - 0s - loss: 0.1268 - accuracy: 0.9740 - val_loss: 1.1853 - val_accuracy: 0.6716
Epoch 19/80
9/9 - 0s - loss: 0.0896 - accuracy: 0.9888 - val_loss: 1.0863 - val_accuracy: 0.6716
Epoch 20/80
9/9 - 0s - loss: 0.0629 - accuracy: 0.9926 - val_loss: 1.1575 - val_accuracy: 0.6567
Epoch 21/80
9/9 - 0s - loss: 0.0453 - accuracy: 0.9963 - val_loss: 1.1102 - val_accuracy: 0.6866
Epoch 22/80
9/9 - 0s - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.2219 - val_accuracy: 0.6269
Epoch 23/80
9/9 - 0s - loss: 0.0339 - accuracy: 0.9926 - val_loss: 1.1607 - val_accuracy: 0.6716
Epoch 24/80
9/9 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.2318 - val_accuracy: 0.6716
Epoch 25/80
9/9 - 0s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.6716
Epoch 26/80
9/9 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.2083 - val_accuracy: 0.6866
Epoch 27/80
9/9 - 0s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.6567
Epoch 28/80
9/9 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.6567
Epoch 29/80
9/9 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.2858 - val_accuracy: 0.6716
Epoch 30/80
9/9 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.6866
Epoch 31/80
9/9 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.6716
Epoch 32/80
9/9 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.6866
Epoch 33/80
9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.6866
Epoch 34/80
9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.6866
Epoch 35/80
9/9 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3804 - val_accuracy: 0.6866
Epoch 36/80
9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.6866
Epoch 37/80
9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.6866
Epoch 38/80
9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4192 - val_accuracy: 0.6866
Epoch 39/80
9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4316 - val_accuracy: 0.6866
Epoch 40/80
9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4348 - val_accuracy: 0.6716
Epoch 41/80
9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4460 - val_accuracy: 0.6716
Epoch 00041: early stopping
best epoch: 21  loss: 1.1101664304733276  acc: 0.6865671873092651
[0.7649983167648315, 1.1687507629394531, 1.0449234247207642, 1.1101664304733276] [0.6764705777168274, 0.641791045665741, 0.6716417670249939, 0.6865671873092651]
Accuracy:0.687

Confusion matrix:
 [[12  1  1  1]
 [ 2 12  2  0]
 [ 1  5 11  1]
 [ 2  3  2 11]]

#####FOLDER NUMBER: 5
Epoch 1/80
9/9 - 1s - loss: 1.3345 - accuracy: 0.3346 - val_loss: 1.2972 - val_accuracy: 0.3284
Epoch 2/80
9/9 - 0s - loss: 1.1257 - accuracy: 0.4944 - val_loss: 1.1832 - val_accuracy: 0.4627
Epoch 3/80
9/9 - 0s - loss: 0.9888 - accuracy: 0.5874 - val_loss: 1.1360 - val_accuracy: 0.4925
Epoch 4/80
9/9 - 0s - loss: 0.8857 - accuracy: 0.6283 - val_loss: 1.1045 - val_accuracy: 0.4925
Epoch 5/80
9/9 - 1s - loss: 0.8375 - accuracy: 0.6283 - val_loss: 1.1179 - val_accuracy: 0.5373
Epoch 6/80
9/9 - 1s - loss: 0.7739 - accuracy: 0.6877 - val_loss: 1.0414 - val_accuracy: 0.5373
Epoch 7/80
9/9 - 1s - loss: 0.7071 - accuracy: 0.7063 - val_loss: 1.0007 - val_accuracy: 0.6269
Epoch 8/80
9/9 - 1s - loss: 0.6426 - accuracy: 0.7509 - val_loss: 1.0337 - val_accuracy: 0.5970
Epoch 9/80
9/9 - 1s - loss: 0.5945 - accuracy: 0.7770 - val_loss: 0.9210 - val_accuracy: 0.6119
Epoch 10/80
9/9 - 1s - loss: 0.5258 - accuracy: 0.8178 - val_loss: 0.9100 - val_accuracy: 0.6418
Epoch 11/80
9/9 - 1s - loss: 0.4974 - accuracy: 0.8104 - val_loss: 0.9718 - val_accuracy: 0.5970
Epoch 12/80
9/9 - 0s - loss: 0.4265 - accuracy: 0.8476 - val_loss: 0.8846 - val_accuracy: 0.6269
Epoch 13/80
9/9 - 1s - loss: 0.3467 - accuracy: 0.8922 - val_loss: 0.8808 - val_accuracy: 0.6269
Epoch 14/80
9/9 - 1s - loss: 0.2870 - accuracy: 0.9257 - val_loss: 0.8327 - val_accuracy: 0.6418
Epoch 15/80
9/9 - 1s - loss: 0.2525 - accuracy: 0.9257 - val_loss: 0.8588 - val_accuracy: 0.6567
Epoch 16/80
9/9 - 1s - loss: 0.1806 - accuracy: 0.9777 - val_loss: 0.9816 - val_accuracy: 0.6269
Epoch 17/80
9/9 - 1s - loss: 0.2976 - accuracy: 0.9071 - val_loss: 0.9575 - val_accuracy: 0.6716
Epoch 18/80
9/9 - 1s - loss: 0.2652 - accuracy: 0.9108 - val_loss: 0.9696 - val_accuracy: 0.6418
Epoch 19/80
9/9 - 0s - loss: 0.2174 - accuracy: 0.9182 - val_loss: 0.9783 - val_accuracy: 0.6567
Epoch 20/80
9/9 - 1s - loss: 0.1696 - accuracy: 0.9480 - val_loss: 0.8573 - val_accuracy: 0.7015
Epoch 21/80
9/9 - 0s - loss: 0.1186 - accuracy: 0.9888 - val_loss: 0.9451 - val_accuracy: 0.6716
Epoch 22/80
9/9 - 0s - loss: 0.0719 - accuracy: 0.9963 - val_loss: 0.9833 - val_accuracy: 0.6269
Epoch 23/80
9/9 - 0s - loss: 0.0568 - accuracy: 0.9963 - val_loss: 0.9485 - val_accuracy: 0.6716
Epoch 24/80
9/9 - 0s - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.6567
Epoch 25/80
9/9 - 0s - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6567
Epoch 26/80
9/9 - 0s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 0.6418
Epoch 27/80
9/9 - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.6418
Epoch 28/80
9/9 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.6567
Epoch 29/80
9/9 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 0.6567
Epoch 30/80
9/9 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.6418
Epoch 31/80
9/9 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.6716
Epoch 32/80
9/9 - 0s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.6567
Epoch 33/80
9/9 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.6567
Epoch 34/80
9/9 - 0s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.6716
Epoch 35/80
9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.6716
Epoch 36/80
9/9 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.6567
Epoch 37/80
9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.6567
Epoch 38/80
9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.6716
Epoch 39/80
9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6866
Epoch 40/80
9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9831 - val_accuracy: 0.6716
Epoch 00040: early stopping
best epoch: 20  loss: 0.8573130369186401  acc: 0.7014925479888916
[0.7649983167648315, 1.1687507629394531, 1.0449234247207642, 1.1101664304733276, 0.8573130369186401] [0.6764705777168274, 0.641791045665741, 0.6716417670249939, 0.6865671873092651, 0.7014925479888916]
Accuracy:0.701

Confusion matrix:
 [[14  1  2  2]
 [ 0 12  2  4]
 [ 1  1 13  0]
 [ 2  3  2  8]]


 ############# AVERAGE EVALUATIONS ############

######### MEAN LOSS OVER THE 5 FOLDERS: 0.9892303943634033  ###########
######### MEAN ACCURACY OVER THE 5 FOLDERS: 0.6755926251411438  ###########
######### LOSS STANDARD DEVIATION OVER THE 5 FOLDERS: 0.15338644986662214  ###########
######### ACC STANDARD DEVIATION OVER THE 5 FOLDERS: 0.01974929808328549  ###########

####MEAN LOSSES OF THE FIRST  1  ITERATIONS:  [0.9892303943634033]  MEAN ACC OF THE FIRST  1  ITERATIONS:  [0.6755926251411438]  #####
####LOSSES STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  ACC STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  #####

####LOSS OVER  1  ITERATIONS:  0.9892303943634033  ##### ACC OVER  1  ITERATIONS: 0.6755926251411438  #####
####LOSS STANDARD DEVIATION OVER  1  ITERATIONS:  0.0  ACC STANDARD DEVIATION OVER  1  ITERATIONS: 0.0 #####
