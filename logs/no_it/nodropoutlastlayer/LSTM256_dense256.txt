2020-09-24 14:52:07.695646: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-09-24 14:52:07.696479: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-09-24 14:52:11.308596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x237e2bf5480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-24 14:52:11.308856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-24 14:52:11.310108: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-09-24 14:52:11.310322: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-24 14:52:11.315019: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-OVHAIFS
2020-09-24 14:52:11.316488: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-OVHAIFS
WARNING:tensorflow:From C:/Users/mp95/PycharmProjects/Thesis/model/lstm_parselmouth4.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Using TensorFlow backend.
curdir: C:\Users\mp95\PycharmProjects\Thesis\model
started reading folder Sad
  0%|          | 0/84 [00:00<?, ?it/s] 21%|???       | 18/84 [00:00<00:00, 174.91it/s] 42%|?????     | 35/84 [00:00<00:00, 168.30it/s] 61%|??????    | 51/84 [00:00<00:00, 165.25it/s]
EXECUTION PARAMETERS: {NUMBER OF FOLDERS:  5 }-{NUMBER OF EPOCHS:  80 }-{NUMBER OF ROUTINE ITERATIONS:  1 }-{BATCH SIZE :  32 }-{SIGNAL MODE:  fp }-{AUGMENT: Sad }-{FEATURES:  mfcc }-{EMOTIONS: ('Sad', 'Happy', 'Angry', 'Neutral') }

####ITERATION NUMBER:  1

#####FOLDER NUMBER: 1
Starting LSTM
 79%|????????  | 66/84 [00:00<00:00, 158.38it/s] 95%|??????????| 80/84 [00:00<00:00, 146.67it/s]100%|??????????| 84/84 [00:00<00:00, 151.75it/s]
ended reading folder Sad
started reading folder Happy
  0%|          | 0/84 [00:00<?, ?it/s] 20%|??        | 17/84 [00:00<00:00, 163.60it/s] 38%|????      | 32/84 [00:00<00:00, 157.31it/s] 57%|??????    | 48/84 [00:00<00:00, 157.22it/s] 76%|????????  | 64/84 [00:00<00:00, 155.32it/s] 96%|??????????| 81/84 [00:00<00:00, 158.16it/s]100%|??????????| 84/84 [00:00<00:00, 156.56it/s]
ended reading folder Happy
started reading folder Angry
  0%|          | 0/84 [00:00<?, ?it/s] 20%|??        | 17/84 [00:00<00:00, 162.04it/s] 40%|????      | 34/84 [00:00<00:00, 160.21it/s] 61%|??????    | 51/84 [00:00<00:00, 160.76it/s] 79%|????????  | 66/84 [00:00<00:00, 155.94it/s] 98%|??????????| 82/84 [00:00<00:00, 154.45it/s]100%|??????????| 84/84 [00:00<00:00, 156.27it/s]
ended reading folder Angry
started reading folder Neutral
  0%|          | 0/84 [00:00<?, ?it/s] 21%|???       | 18/84 [00:00<00:00, 169.96it/s] 42%|?????     | 35/84 [00:00<00:00, 166.93it/s] 63%|???????   | 53/84 [00:00<00:00, 169.16it/s] 83%|????????? | 70/84 [00:00<00:00, 169.36it/s]100%|??????????| 84/84 [00:00<00:00, 169.27it/s]
ended reading folder Neutral
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 44, 13)            0         
_________________________________________________________________
lstm (LSTM)                  (None, 256)               276480    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 256)               65792     
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1028      
=================================================================
Total params: 343,300
Trainable params: 343,300
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/80
9/9 - 4s - loss: 1.3682 - accuracy: 0.3358 - val_loss: 1.1341 - val_accuracy: 0.4118
Epoch 2/80
9/9 - 1s - loss: 1.1257 - accuracy: 0.4851 - val_loss: 1.0781 - val_accuracy: 0.4118
Epoch 3/80
9/9 - 2s - loss: 0.9925 - accuracy: 0.5187 - val_loss: 1.0351 - val_accuracy: 0.5000
Epoch 4/80
9/9 - 1s - loss: 0.9117 - accuracy: 0.5933 - val_loss: 0.9444 - val_accuracy: 0.5882
Epoch 5/80
9/9 - 2s - loss: 0.8686 - accuracy: 0.6194 - val_loss: 0.9988 - val_accuracy: 0.5147
Epoch 6/80
9/9 - 2s - loss: 0.7761 - accuracy: 0.6455 - val_loss: 0.9275 - val_accuracy: 0.5441
Epoch 7/80
9/9 - 2s - loss: 0.7123 - accuracy: 0.6791 - val_loss: 0.8867 - val_accuracy: 0.5882
Epoch 8/80
9/9 - 2s - loss: 0.6239 - accuracy: 0.7388 - val_loss: 0.8130 - val_accuracy: 0.6912
Epoch 9/80
9/9 - 2s - loss: 0.4976 - accuracy: 0.8172 - val_loss: 0.8420 - val_accuracy: 0.5882
Epoch 10/80
9/9 - 2s - loss: 0.4666 - accuracy: 0.8097 - val_loss: 0.8211 - val_accuracy: 0.6471
Epoch 11/80
9/9 - 2s - loss: 0.4225 - accuracy: 0.8172 - val_loss: 0.7620 - val_accuracy: 0.6471
Epoch 12/80
9/9 - 2s - loss: 0.3286 - accuracy: 0.8694 - val_loss: 0.7728 - val_accuracy: 0.6618
Epoch 13/80
9/9 - 2s - loss: 0.3138 - accuracy: 0.8582 - val_loss: 1.2124 - val_accuracy: 0.5882
Epoch 14/80
9/9 - 2s - loss: 0.3952 - accuracy: 0.8433 - val_loss: 1.0259 - val_accuracy: 0.6029
Epoch 15/80
9/9 - 2s - loss: 0.3055 - accuracy: 0.8769 - val_loss: 0.8844 - val_accuracy: 0.6324
Epoch 16/80
9/9 - 3s - loss: 0.1793 - accuracy: 0.9440 - val_loss: 1.1295 - val_accuracy: 0.5441
Epoch 17/80
9/9 - 2s - loss: 0.2001 - accuracy: 0.9179 - val_loss: 0.9148 - val_accuracy: 0.6618
Epoch 18/80
9/9 - 2s - loss: 0.1549 - accuracy: 0.9515 - val_loss: 0.7200 - val_accuracy: 0.7206
Epoch 19/80
9/9 - 2s - loss: 0.1609 - accuracy: 0.9515 - val_loss: 1.4051 - val_accuracy: 0.5882
Epoch 20/80
9/9 - 2s - loss: 0.1697 - accuracy: 0.9328 - val_loss: 0.9473 - val_accuracy: 0.6912
Epoch 21/80
9/9 - 3s - loss: 0.1734 - accuracy: 0.9478 - val_loss: 1.4396 - val_accuracy: 0.5441
Epoch 22/80
9/9 - 2s - loss: 0.1772 - accuracy: 0.9328 - val_loss: 0.8787 - val_accuracy: 0.6765
Epoch 23/80
9/9 - 2s - loss: 0.0925 - accuracy: 0.9627 - val_loss: 1.2456 - val_accuracy: 0.5882
Epoch 24/80
9/9 - 2s - loss: 0.0831 - accuracy: 0.9776 - val_loss: 0.7599 - val_accuracy: 0.7647
Epoch 25/80
9/9 - 2s - loss: 0.0544 - accuracy: 0.9888 - val_loss: 0.8894 - val_accuracy: 0.6912
Epoch 26/80
9/9 - 2s - loss: 0.0365 - accuracy: 0.9925 - val_loss: 0.9933 - val_accuracy: 0.6912
Epoch 27/80
9/9 - 2s - loss: 0.0270 - accuracy: 0.9963 - val_loss: 1.1262 - val_accuracy: 0.6912
Epoch 28/80
9/9 - 2s - loss: 0.0195 - accuracy: 0.9963 - val_loss: 1.1219 - val_accuracy: 0.7353
Epoch 29/80
9/9 - 2s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.6912
Epoch 30/80
9/9 - 2s - loss: 0.0238 - accuracy: 0.9963 - val_loss: 1.2970 - val_accuracy: 0.6765
Epoch 31/80
9/9 - 2s - loss: 0.0161 - accuracy: 0.9925 - val_loss: 1.2719 - val_accuracy: 0.7059
Epoch 32/80
9/9 - 2s - loss: 0.0202 - accuracy: 0.9925 - val_loss: 1.3176 - val_accuracy: 0.7206
Epoch 33/80
9/9 - 2s - loss: 0.0192 - accuracy: 0.9963 - val_loss: 1.3221 - val_accuracy: 0.6912
Epoch 34/80
9/9 - 2s - loss: 0.0100 - accuracy: 0.9963 - val_loss: 1.4872 - val_accuracy: 0.6471
Epoch 35/80
9/9 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.6765
Epoch 36/80
9/9 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.7059
Epoch 37/80
9/9 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 0.6912
Epoch 38/80
9/9 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3913 - val_accuracy: 0.7059
Epoch 39/80
9/9 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.6618
Epoch 40/80
9/9 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.6618
Epoch 41/80
9/9 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5849 - val_accuracy: 0.6765
Epoch 42/80
9/9 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.6618
Epoch 43/80
9/9 - 3s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6024 - val_accuracy: 0.6765
Epoch 44/80
9/9 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6242 - val_accuracy: 0.6765
Epoch 00044: early stopping
best epoch: 24  loss: 0.7599158883094788  acc: 0.7647058963775635
[0.7599158883094788] [0.7647058963775635]
Accuracy:0.765

Confusion matrix:
 [[ 8  0  0  4]
 [ 0 17  5  2]
 [ 2  0 14  0]
 [ 1  2  0 13]]

#####FOLDER NUMBER: 2
Epoch 1/80
9/9 - 2s - loss: 1.4147 - accuracy: 0.2491 - val_loss: 1.2212 - val_accuracy: 0.3731
Epoch 2/80
9/9 - 2s - loss: 1.1521 - accuracy: 0.4572 - val_loss: 1.1018 - val_accuracy: 0.3881
Epoch 3/80
9/9 - 2s - loss: 1.1237 - accuracy: 0.4721 - val_loss: 1.1096 - val_accuracy: 0.5224
Epoch 4/80
9/9 - 2s - loss: 1.0174 - accuracy: 0.5539 - val_loss: 0.9574 - val_accuracy: 0.5522
Epoch 5/80
9/9 - 2s - loss: 0.9938 - accuracy: 0.5316 - val_loss: 0.9301 - val_accuracy: 0.5672
Epoch 6/80
9/9 - 2s - loss: 0.8169 - accuracy: 0.6877 - val_loss: 0.9485 - val_accuracy: 0.5672
Epoch 7/80
9/9 - 2s - loss: 0.7638 - accuracy: 0.6617 - val_loss: 1.1479 - val_accuracy: 0.5075
Epoch 8/80
9/9 - 2s - loss: 0.7136 - accuracy: 0.7361 - val_loss: 1.0477 - val_accuracy: 0.5672
Epoch 9/80
9/9 - 2s - loss: 0.5984 - accuracy: 0.7658 - val_loss: 0.9332 - val_accuracy: 0.5970
Epoch 10/80
9/9 - 2s - loss: 0.5323 - accuracy: 0.7955 - val_loss: 0.9791 - val_accuracy: 0.5821
Epoch 11/80
9/9 - 2s - loss: 0.4638 - accuracy: 0.8178 - val_loss: 0.9967 - val_accuracy: 0.6269
Epoch 12/80
9/9 - 2s - loss: 0.4502 - accuracy: 0.8104 - val_loss: 1.1551 - val_accuracy: 0.6119
Epoch 13/80
9/9 - 2s - loss: 0.4294 - accuracy: 0.8327 - val_loss: 1.1372 - val_accuracy: 0.5522
Epoch 14/80
9/9 - 2s - loss: 0.3989 - accuracy: 0.8290 - val_loss: 1.2040 - val_accuracy: 0.6269
Epoch 15/80
9/9 - 2s - loss: 0.3651 - accuracy: 0.8625 - val_loss: 1.1355 - val_accuracy: 0.5970
Epoch 16/80
9/9 - 1s - loss: 0.2450 - accuracy: 0.9182 - val_loss: 1.2476 - val_accuracy: 0.5821
Epoch 17/80
9/9 - 1s - loss: 0.2409 - accuracy: 0.9033 - val_loss: 1.2792 - val_accuracy: 0.5970
Epoch 18/80
9/9 - 1s - loss: 0.2507 - accuracy: 0.8922 - val_loss: 1.2609 - val_accuracy: 0.6418
Epoch 19/80
9/9 - 1s - loss: 0.2199 - accuracy: 0.9257 - val_loss: 1.4029 - val_accuracy: 0.5821
Epoch 20/80
9/9 - 1s - loss: 0.1584 - accuracy: 0.9442 - val_loss: 1.2431 - val_accuracy: 0.5672
Epoch 21/80
9/9 - 1s - loss: 0.1272 - accuracy: 0.9591 - val_loss: 1.1390 - val_accuracy: 0.6716
Epoch 22/80
9/9 - 1s - loss: 0.0880 - accuracy: 0.9814 - val_loss: 1.2969 - val_accuracy: 0.6418
Epoch 23/80
9/9 - 2s - loss: 0.0868 - accuracy: 0.9777 - val_loss: 1.5496 - val_accuracy: 0.5970
Epoch 24/80
9/9 - 2s - loss: 0.0846 - accuracy: 0.9777 - val_loss: 1.3807 - val_accuracy: 0.6716
Epoch 25/80
9/9 - 2s - loss: 0.0438 - accuracy: 0.9926 - val_loss: 1.4496 - val_accuracy: 0.6866
Epoch 26/80
9/9 - 2s - loss: 0.0412 - accuracy: 0.9888 - val_loss: 1.6557 - val_accuracy: 0.6269
Epoch 27/80
9/9 - 2s - loss: 0.0450 - accuracy: 0.9888 - val_loss: 1.6125 - val_accuracy: 0.6269
Epoch 28/80
9/9 - 2s - loss: 0.0981 - accuracy: 0.9703 - val_loss: 1.5306 - val_accuracy: 0.5522
Epoch 29/80
9/9 - 2s - loss: 0.0792 - accuracy: 0.9740 - val_loss: 1.8934 - val_accuracy: 0.5821
Epoch 30/80
9/9 - 3s - loss: 0.0555 - accuracy: 0.9851 - val_loss: 1.8174 - val_accuracy: 0.5821
Epoch 31/80
9/9 - 3s - loss: 0.1075 - accuracy: 0.9628 - val_loss: 1.3601 - val_accuracy: 0.6866
Epoch 32/80
9/9 - 2s - loss: 0.0486 - accuracy: 0.9851 - val_loss: 1.3763 - val_accuracy: 0.6269
Epoch 33/80
9/9 - 2s - loss: 0.0220 - accuracy: 0.9963 - val_loss: 1.7138 - val_accuracy: 0.6418
Epoch 34/80
9/9 - 3s - loss: 0.0188 - accuracy: 0.9963 - val_loss: 1.5247 - val_accuracy: 0.6269
Epoch 35/80
9/9 - 3s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.6418
Epoch 36/80
9/9 - 3s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5618 - val_accuracy: 0.6866
Epoch 37/80
9/9 - 3s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.6450 - val_accuracy: 0.6716
Epoch 38/80
9/9 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.6716
Epoch 39/80
9/9 - 3s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.6626 - val_accuracy: 0.6716
Epoch 40/80
9/9 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6705 - val_accuracy: 0.6716
Epoch 41/80
9/9 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.6716
Epoch 42/80
9/9 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7635 - val_accuracy: 0.6418
Epoch 43/80
9/9 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8334 - val_accuracy: 0.6418
Epoch 44/80
9/9 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8580 - val_accuracy: 0.6269
Epoch 45/80
9/9 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8359 - val_accuracy: 0.5821
Epoch 00045: early stopping
best epoch: 25  loss: 1.4495731592178345  acc: 0.6865671873092651
[0.7599158883094788, 1.4495731592178345] [0.7647058963775635, 0.6865671873092651]
Accuracy:0.687

Confusion matrix:
 [[11  1  2  3]
 [ 1 11  2  0]
 [ 0  4 13  3]
 [ 5  0  0 11]]

#####FOLDER NUMBER: 3
Epoch 1/80
9/9 - 2s - loss: 1.4322 - accuracy: 0.2862 - val_loss: 1.1496 - val_accuracy: 0.5224
Epoch 2/80
9/9 - 1s - loss: 1.1749 - accuracy: 0.4535 - val_loss: 1.1966 - val_accuracy: 0.4179
Epoch 3/80
9/9 - 2s - loss: 1.0771 - accuracy: 0.4721 - val_loss: 1.1398 - val_accuracy: 0.4478
Epoch 4/80
9/9 - 2s - loss: 0.9766 - accuracy: 0.5985 - val_loss: 1.0387 - val_accuracy: 0.4776
Epoch 5/80
9/9 - 1s - loss: 0.9146 - accuracy: 0.5613 - val_loss: 1.2659 - val_accuracy: 0.4627
Epoch 6/80
9/9 - 2s - loss: 0.9350 - accuracy: 0.5688 - val_loss: 1.1465 - val_accuracy: 0.4925
Epoch 7/80
9/9 - 2s - loss: 0.8217 - accuracy: 0.6766 - val_loss: 1.0732 - val_accuracy: 0.4627
Epoch 8/80
9/9 - 1s - loss: 0.7761 - accuracy: 0.6914 - val_loss: 1.1952 - val_accuracy: 0.5224
Epoch 9/80
9/9 - 1s - loss: 0.7542 - accuracy: 0.6617 - val_loss: 1.0767 - val_accuracy: 0.5224
Epoch 10/80
9/9 - 1s - loss: 0.6070 - accuracy: 0.7546 - val_loss: 0.9279 - val_accuracy: 0.5821
Epoch 11/80
9/9 - 2s - loss: 0.6422 - accuracy: 0.7323 - val_loss: 1.2489 - val_accuracy: 0.4925
Epoch 12/80
9/9 - 2s - loss: 0.5463 - accuracy: 0.7955 - val_loss: 0.9310 - val_accuracy: 0.6567
Epoch 13/80
9/9 - 2s - loss: 0.5068 - accuracy: 0.7993 - val_loss: 0.9353 - val_accuracy: 0.6418
Epoch 14/80
9/9 - 2s - loss: 0.4168 - accuracy: 0.8290 - val_loss: 0.9511 - val_accuracy: 0.6866
Epoch 15/80
9/9 - 2s - loss: 0.3982 - accuracy: 0.8476 - val_loss: 0.8328 - val_accuracy: 0.6866
Epoch 16/80
9/9 - 2s - loss: 0.2982 - accuracy: 0.8773 - val_loss: 0.9443 - val_accuracy: 0.6567
Epoch 17/80
9/9 - 2s - loss: 0.2791 - accuracy: 0.8922 - val_loss: 0.9265 - val_accuracy: 0.5970
Epoch 18/80
9/9 - 2s - loss: 0.2840 - accuracy: 0.8959 - val_loss: 0.9063 - val_accuracy: 0.7164
Epoch 19/80
9/9 - 2s - loss: 0.2351 - accuracy: 0.9294 - val_loss: 0.9856 - val_accuracy: 0.6716
Epoch 20/80
9/9 - 3s - loss: 0.1729 - accuracy: 0.9442 - val_loss: 1.0212 - val_accuracy: 0.6418
Epoch 21/80
9/9 - 2s - loss: 0.1532 - accuracy: 0.9517 - val_loss: 0.9548 - val_accuracy: 0.6716
Epoch 22/80
9/9 - 2s - loss: 0.1079 - accuracy: 0.9628 - val_loss: 0.9524 - val_accuracy: 0.7015
Epoch 23/80
9/9 - 2s - loss: 0.1069 - accuracy: 0.9740 - val_loss: 0.9127 - val_accuracy: 0.6716
Epoch 24/80
9/9 - 2s - loss: 0.1047 - accuracy: 0.9665 - val_loss: 1.3002 - val_accuracy: 0.5672
Epoch 25/80
9/9 - 3s - loss: 0.2307 - accuracy: 0.9182 - val_loss: 1.4496 - val_accuracy: 0.5821
Epoch 26/80
9/9 - 3s - loss: 0.1891 - accuracy: 0.9368 - val_loss: 1.1962 - val_accuracy: 0.6269
Epoch 27/80
9/9 - 2s - loss: 0.1317 - accuracy: 0.9442 - val_loss: 0.8695 - val_accuracy: 0.6716
Epoch 28/80
9/9 - 2s - loss: 0.0907 - accuracy: 0.9665 - val_loss: 1.2379 - val_accuracy: 0.7015
Epoch 29/80
9/9 - 2s - loss: 0.0962 - accuracy: 0.9703 - val_loss: 1.3382 - val_accuracy: 0.6269
Epoch 30/80
9/9 - 2s - loss: 0.0803 - accuracy: 0.9628 - val_loss: 1.1416 - val_accuracy: 0.7164
Epoch 31/80
9/9 - 2s - loss: 0.1096 - accuracy: 0.9554 - val_loss: 1.3444 - val_accuracy: 0.6418
Epoch 32/80
9/9 - 2s - loss: 0.0616 - accuracy: 0.9851 - val_loss: 0.9679 - val_accuracy: 0.6866
Epoch 33/80
9/9 - 2s - loss: 0.0566 - accuracy: 0.9814 - val_loss: 1.2652 - val_accuracy: 0.7015
Epoch 34/80
9/9 - 3s - loss: 0.0404 - accuracy: 0.9888 - val_loss: 1.3512 - val_accuracy: 0.6418
Epoch 35/80
9/9 - 2s - loss: 0.0168 - accuracy: 0.9963 - val_loss: 1.2975 - val_accuracy: 0.6567
Epoch 36/80
9/9 - 2s - loss: 0.0245 - accuracy: 0.9926 - val_loss: 1.1644 - val_accuracy: 0.6866
Epoch 37/80
9/9 - 3s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.7015
Epoch 38/80
9/9 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.7015
Epoch 00038: early stopping
best epoch: 18  loss: 0.9062790274620056  acc: 0.7164179086685181
[0.7599158883094788, 1.4495731592178345, 0.9062790274620056] [0.7647058963775635, 0.6865671873092651, 0.7164179086685181]
Accuracy:0.716

Confusion matrix:
 [[20  0  0  1]
 [ 1  7  2  2]
 [ 0  6  7  2]
 [ 2  2  1 14]]

#####FOLDER NUMBER: 4
Epoch 1/80
9/9 - 2s - loss: 1.3563 - accuracy: 0.3048 - val_loss: 1.2040 - val_accuracy: 0.4925
Epoch 2/80
9/9 - 2s - loss: 1.1280 - accuracy: 0.5056 - val_loss: 1.2170 - val_accuracy: 0.4328
Epoch 3/80
9/9 - 2s - loss: 1.1283 - accuracy: 0.4944 - val_loss: 1.1215 - val_accuracy: 0.5224
Epoch 4/80
9/9 - 2s - loss: 1.0612 - accuracy: 0.4796 - val_loss: 1.0996 - val_accuracy: 0.5522
Epoch 5/80
9/9 - 1s - loss: 0.9382 - accuracy: 0.5725 - val_loss: 1.0533 - val_accuracy: 0.5522
Epoch 6/80
9/9 - 1s - loss: 0.8138 - accuracy: 0.6506 - val_loss: 1.0351 - val_accuracy: 0.5672
Epoch 7/80
9/9 - 1s - loss: 0.7214 - accuracy: 0.6766 - val_loss: 1.0569 - val_accuracy: 0.5821
Epoch 8/80
9/9 - 1s - loss: 0.7261 - accuracy: 0.6803 - val_loss: 1.1498 - val_accuracy: 0.5373
Epoch 9/80
9/9 - 1s - loss: 0.6632 - accuracy: 0.7138 - val_loss: 0.9497 - val_accuracy: 0.6418
Epoch 10/80
9/9 - 1s - loss: 0.6022 - accuracy: 0.7361 - val_loss: 0.9411 - val_accuracy: 0.6119
Epoch 11/80
9/9 - 1s - loss: 0.4851 - accuracy: 0.7993 - val_loss: 1.0412 - val_accuracy: 0.5970
Epoch 12/80
9/9 - 1s - loss: 0.4401 - accuracy: 0.8104 - val_loss: 1.3439 - val_accuracy: 0.5970
Epoch 13/80
9/9 - 2s - loss: 0.4023 - accuracy: 0.8290 - val_loss: 1.0593 - val_accuracy: 0.6567
Epoch 14/80
9/9 - 1s - loss: 0.3086 - accuracy: 0.8885 - val_loss: 1.2096 - val_accuracy: 0.6716
Epoch 15/80
9/9 - 1s - loss: 0.3065 - accuracy: 0.8662 - val_loss: 1.4850 - val_accuracy: 0.6119
Epoch 16/80
9/9 - 1s - loss: 0.3493 - accuracy: 0.8513 - val_loss: 0.9325 - val_accuracy: 0.7015
Epoch 17/80
9/9 - 2s - loss: 0.2440 - accuracy: 0.9108 - val_loss: 1.0337 - val_accuracy: 0.6269
Epoch 18/80
9/9 - 2s - loss: 0.2488 - accuracy: 0.9033 - val_loss: 1.1978 - val_accuracy: 0.6567
Epoch 19/80
9/9 - 2s - loss: 0.2529 - accuracy: 0.9071 - val_loss: 1.6153 - val_accuracy: 0.5522
Epoch 20/80
9/9 - 2s - loss: 0.2529 - accuracy: 0.8996 - val_loss: 1.2069 - val_accuracy: 0.6716
Epoch 21/80
9/9 - 2s - loss: 0.1957 - accuracy: 0.9182 - val_loss: 1.4398 - val_accuracy: 0.6269
Epoch 22/80
9/9 - 2s - loss: 0.1828 - accuracy: 0.9442 - val_loss: 1.2190 - val_accuracy: 0.6567
Epoch 23/80
9/9 - 2s - loss: 0.1863 - accuracy: 0.9182 - val_loss: 1.2870 - val_accuracy: 0.5821
Epoch 24/80
9/9 - 2s - loss: 0.1697 - accuracy: 0.9331 - val_loss: 1.6193 - val_accuracy: 0.5821
Epoch 25/80
9/9 - 2s - loss: 0.1694 - accuracy: 0.9331 - val_loss: 1.5080 - val_accuracy: 0.5672
Epoch 26/80
9/9 - 2s - loss: 0.3063 - accuracy: 0.8959 - val_loss: 1.2070 - val_accuracy: 0.6567
Epoch 27/80
9/9 - 2s - loss: 0.1960 - accuracy: 0.9257 - val_loss: 1.2876 - val_accuracy: 0.6567
Epoch 28/80
9/9 - 2s - loss: 0.1065 - accuracy: 0.9703 - val_loss: 1.2466 - val_accuracy: 0.6866
Epoch 29/80
9/9 - 2s - loss: 0.0908 - accuracy: 0.9703 - val_loss: 1.5567 - val_accuracy: 0.5970
Epoch 30/80
9/9 - 2s - loss: 0.0628 - accuracy: 0.9814 - val_loss: 1.2056 - val_accuracy: 0.6567
Epoch 31/80
9/9 - 3s - loss: 0.0588 - accuracy: 0.9888 - val_loss: 1.2787 - val_accuracy: 0.6418
Epoch 32/80
9/9 - 2s - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.4992 - val_accuracy: 0.6418
Epoch 33/80
9/9 - 2s - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.6269
Epoch 34/80
9/9 - 2s - loss: 0.0178 - accuracy: 0.9963 - val_loss: 1.6250 - val_accuracy: 0.6269
Epoch 35/80
9/9 - 2s - loss: 0.0169 - accuracy: 0.9963 - val_loss: 1.5965 - val_accuracy: 0.6269
Epoch 36/80
9/9 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.6375 - val_accuracy: 0.6269
Epoch 00036: early stopping
best epoch: 16  loss: 0.9325380325317383  acc: 0.7014925479888916
[0.7599158883094788, 1.4495731592178345, 0.9062790274620056, 0.9325380325317383] [0.7647058963775635, 0.6865671873092651, 0.7164179086685181, 0.7014925479888916]
Accuracy:0.701

Confusion matrix:
 [[13  0  0  2]
 [ 0  9  3  4]
 [ 1  3 12  2]
 [ 2  2  1 13]]

#####FOLDER NUMBER: 5
Epoch 1/80
9/9 - 2s - loss: 1.4272 - accuracy: 0.2974 - val_loss: 1.2088 - val_accuracy: 0.4328
Epoch 2/80
9/9 - 2s - loss: 1.1320 - accuracy: 0.4610 - val_loss: 1.1808 - val_accuracy: 0.5075
Epoch 3/80
9/9 - 1s - loss: 1.0597 - accuracy: 0.4721 - val_loss: 1.1481 - val_accuracy: 0.4776
Epoch 4/80
9/9 - 1s - loss: 0.9787 - accuracy: 0.5539 - val_loss: 1.1481 - val_accuracy: 0.4478
Epoch 5/80
9/9 - 1s - loss: 0.9020 - accuracy: 0.5799 - val_loss: 1.3300 - val_accuracy: 0.5373
Epoch 6/80
9/9 - 1s - loss: 0.9975 - accuracy: 0.6059 - val_loss: 1.0833 - val_accuracy: 0.5522
Epoch 7/80
9/9 - 1s - loss: 0.9245 - accuracy: 0.6097 - val_loss: 1.1007 - val_accuracy: 0.4776
Epoch 8/80
9/9 - 1s - loss: 0.8087 - accuracy: 0.6617 - val_loss: 1.0005 - val_accuracy: 0.6716
Epoch 9/80
9/9 - 1s - loss: 0.8017 - accuracy: 0.6691 - val_loss: 0.8863 - val_accuracy: 0.6269
Epoch 10/80
9/9 - 2s - loss: 0.6959 - accuracy: 0.7026 - val_loss: 0.8731 - val_accuracy: 0.6269
Epoch 11/80
9/9 - 1s - loss: 0.6960 - accuracy: 0.6803 - val_loss: 1.0178 - val_accuracy: 0.6269
Epoch 12/80
9/9 - 2s - loss: 0.5810 - accuracy: 0.7398 - val_loss: 0.8308 - val_accuracy: 0.6269
Epoch 13/80
9/9 - 1s - loss: 0.5378 - accuracy: 0.7918 - val_loss: 0.7356 - val_accuracy: 0.6716
Epoch 14/80
9/9 - 1s - loss: 0.4789 - accuracy: 0.8030 - val_loss: 0.7263 - val_accuracy: 0.7164
Epoch 15/80
9/9 - 1s - loss: 0.4346 - accuracy: 0.8290 - val_loss: 0.9813 - val_accuracy: 0.6716
Epoch 16/80
9/9 - 1s - loss: 0.4320 - accuracy: 0.8216 - val_loss: 0.7733 - val_accuracy: 0.7015
Epoch 17/80
9/9 - 2s - loss: 0.3571 - accuracy: 0.8848 - val_loss: 0.8292 - val_accuracy: 0.6567
Epoch 18/80
9/9 - 1s - loss: 0.4386 - accuracy: 0.8104 - val_loss: 0.9536 - val_accuracy: 0.6567
Epoch 19/80
9/9 - 1s - loss: 0.3786 - accuracy: 0.8662 - val_loss: 0.9930 - val_accuracy: 0.7164
Epoch 20/80
9/9 - 1s - loss: 0.4145 - accuracy: 0.8327 - val_loss: 0.8816 - val_accuracy: 0.7463
Epoch 21/80
9/9 - 1s - loss: 0.3003 - accuracy: 0.8736 - val_loss: 0.7607 - val_accuracy: 0.6716
Epoch 22/80
9/9 - 1s - loss: 0.2065 - accuracy: 0.9182 - val_loss: 0.8353 - val_accuracy: 0.7015
Epoch 23/80
9/9 - 1s - loss: 0.1780 - accuracy: 0.9405 - val_loss: 0.7513 - val_accuracy: 0.7164
Epoch 24/80
9/9 - 1s - loss: 0.1258 - accuracy: 0.9517 - val_loss: 0.7909 - val_accuracy: 0.7015
Epoch 25/80
9/9 - 1s - loss: 0.1145 - accuracy: 0.9554 - val_loss: 0.8497 - val_accuracy: 0.7015
Epoch 26/80
9/9 - 1s - loss: 0.0845 - accuracy: 0.9740 - val_loss: 0.7579 - val_accuracy: 0.7910
Epoch 27/80
9/9 - 1s - loss: 0.0719 - accuracy: 0.9814 - val_loss: 0.8244 - val_accuracy: 0.7164
Epoch 28/80
9/9 - 1s - loss: 0.0439 - accuracy: 0.9926 - val_loss: 0.8036 - val_accuracy: 0.7910
Epoch 29/80
9/9 - 1s - loss: 0.0562 - accuracy: 0.9851 - val_loss: 0.9267 - val_accuracy: 0.7463
Epoch 30/80
9/9 - 1s - loss: 0.0542 - accuracy: 0.9814 - val_loss: 0.9080 - val_accuracy: 0.7761
Epoch 31/80
9/9 - 1s - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.8492 - val_accuracy: 0.7463
Epoch 32/80
9/9 - 1s - loss: 0.0411 - accuracy: 0.9888 - val_loss: 0.9953 - val_accuracy: 0.7463
Epoch 33/80
9/9 - 1s - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.9806 - val_accuracy: 0.7463
Epoch 34/80
9/9 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.7313
Epoch 35/80
9/9 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.7313
Epoch 36/80
9/9 - 1s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.7612
Epoch 37/80
9/9 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.7313
Epoch 38/80
9/9 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.7761
Epoch 39/80
9/9 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0473 - val_accuracy: 0.7761
Epoch 40/80
9/9 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.7761
Epoch 41/80
9/9 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.7612
Epoch 42/80
9/9 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.7761
Epoch 43/80
9/9 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.7761
Epoch 44/80
9/9 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.7761
Epoch 45/80
9/9 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.7612
Epoch 46/80
9/9 - 1s - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.9628 - val_accuracy: 0.7612
Epoch 00046: early stopping
best epoch: 26  loss: 0.7578932642936707  acc: 0.7910447716712952
[0.7599158883094788, 1.4495731592178345, 0.9062790274620056, 0.9325380325317383, 0.7578932642936707] [0.7647058963775635, 0.6865671873092651, 0.7164179086685181, 0.7014925479888916, 0.7910447716712952]
Accuracy:0.791

Confusion matrix:
 [[16  1  1  1]
 [ 0 15  0  3]
 [ 2  2 10  1]
 [ 0  1  2 12]]


 ############# AVERAGE EVALUATIONS ############

######### MEAN LOSS OVER THE 5 FOLDERS: 0.9612398743629456  ###########
######### MEAN ACCURACY OVER THE 5 FOLDERS: 0.7320456624031066  ###########
######### LOSS STANDARD DEVIATION OVER THE 5 FOLDERS: 0.2546350638466197  ###########
######### ACC STANDARD DEVIATION OVER THE 5 FOLDERS: 0.039480620465651595  ###########

####MEAN LOSSES OF THE FIRST  1  ITERATIONS:  [0.9612398743629456]  MEAN ACC OF THE FIRST  1  ITERATIONS:  [0.7320456624031066]  #####
####LOSSES STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  ACC STANDARD DEVIATIONS OF THE FIRST  1  ITERATIONS:  0.0  #####

####LOSS OVER  1  ITERATIONS:  0.9612398743629456  ##### ACC OVER  1  ITERATIONS: 0.7320456624031066  #####
####LOSS STANDARD DEVIATION OVER  1  ITERATIONS:  0.0  ACC STANDARD DEVIATION OVER  1  ITERATIONS: 0.0 #####
